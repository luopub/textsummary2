{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"work-tf-unigru-attn-pgn.ipynb","provenance":[{"file_id":"1bvvzaPmlQiBIWuoQ8eUyX0wq3KChcltS","timestamp":1576832036178}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"WKuYnu6ij7V6","colab_type":"code","colab":{}},"source":["# !cd /content\n","# !pwd\n","# !ls /content"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"sWYxoKtPiwJj","colab_type":"code","outputId":"628c60ae-202f-4804-c624-6b172061ab85","executionInfo":{"status":"ok","timestamp":1577350575971,"user_tz":-480,"elapsed":6267,"user":{"displayName":"Luo Yongliang","photoUrl":"","userId":"08228183385143629193"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["# !pip install jieba\n","# !pip install gensim\n","!nvidia-smi"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Thu Dec 26 08:56:13 2019       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P8     7W /  75W |      0MiB /  7611MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OgumTPAkiwJp","colab_type":"code","outputId":"b121d237-753b-407f-d74c-b2c30809c0c6","executionInfo":{"status":"ok","timestamp":1577350619734,"user_tz":-480,"elapsed":50007,"user":{"displayName":"Luo Yongliang","photoUrl":"","userId":"08228183385143629193"}},"colab":{"base_uri":"https://localhost:8080/","height":207}},"source":["# import pdb\n","\n","from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive\n","\n","data_root = '/gdrive/My Drive/data_tf'\n","# Above is for notebook only\n","# Below is to be moved to py files\n","! ls '/gdrive/My Drive/python-code/文本摘要-01'\n","try:\n","  # %tensorflow_version only exists in Colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n","/gdrive\n","checkpoints  utils\t\t\t     work-tf-unigru-attn.ipynb\n","data\t     work.ipynb\t\t\t     work-tf-unigru-attn-pgn.ipynb\n","result\t     work-tf-unigru-attn-beam.ipynb\n","TensorFlow 2.x selected.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dUq4JDg2iwJw","colab_type":"text"},"source":["# 上面是测试用\n","# ============================================================\n","# 下面要转移到文件里面"]},{"cell_type":"markdown","metadata":{"id":"UU35fUpViwJ7","colab_type":"text"},"source":["# 以下是tensorflow实现带attention 的seq2seq============="]},{"cell_type":"markdown","metadata":{"id":"Izn62hqnxs2s","colab_type":"text"},"source":["# 下面这部分是整理后保存到py文件"]},{"cell_type":"code","metadata":{"id":"PKcreI_w77Q_","colab_type":"code","colab":{}},"source":["# import modules\n","import os\n","import sys\n","import pathlib\n","import pandas as pd\n","import numpy as np\n","import pdb\n","import time\n","import tensorflow as tf\n","\n","project_root = pathlib.Path(r'/gdrive/My Drive/python-code/文本摘要-01')\n","sys.path.append(str(project_root))\n","\n","from utils.config import *\n","from utils.multi_proc_utils import *\n","from utils.data_loader import *\n","from utils.file_utils import *\n","from utils.data_preprocessor import *\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QLk2BfYW79KX","colab_type":"code","colab":{}},"source":["\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n","\n","\n","def loss_function(real, pred, padding_mask):\n","    loss = 0\n","    for t in range(real.shape[1]):\n","        loss_ = loss_object(real[:, t], pred[:, t, :])\n","        mask = tf.cast(padding_mask[:, t], dtype=loss_.dtype)\n","        mask = tf.cast(mask, dtype=loss_.dtype)\n","        loss_ *= mask\n","        loss_ = tf.reduce_mean(loss_)  # batch-wise\n","        loss += loss_\n","    return loss / real.shape[1]\n","\n","def calc_loss(real, pred, padding_mask, attentions, cov_loss_wt, use_coverage):\n","    if use_coverage:\n","        log_loss = loss_function(real, pred, padding_mask)\n","        cov_loss = _coverage_loss(attentions, padding_mask)\n","        return log_loss + cov_loss_wt * cov_loss, log_loss, cov_loss\n","    else:\n","        return loss_function(real, pred, padding_mask), 0, 0\n","\n","def pgn_log_loss_function(real, final_dists, padding_mask):\n","    # Calculate the loss per step\n","    # This is fiddly; we use tf.gather_nd to pick out the probabilities of the gold target words\n","    loss_per_step = []  # will be list length max_dec_steps containing shape (batch_size)\n","    batch_nums = tf.range(0, limit=real.shape[0])  # shape (batch_size)\n","    for dec_step, dist in enumerate(final_dists):\n","        # The indices of the target words. shape (batch_size)\n","        targets = real[:, dec_step]\n","        indices = tf.stack((batch_nums, targets), axis=1)  # shape (batch_size, 2)\n","        gold_probs = tf.gather_nd(dist, indices)  # shape (batch_size). prob of correct words on this step\n","        losses = -tf.math.log(gold_probs)\n","        loss_per_step.append(losses)\n","    # Apply dec_padding_mask and get loss\n","    _loss = _mask_and_avg(loss_per_step, padding_mask)\n","    return _loss\n","\n","\n","def _mask_and_avg(values, padding_mask):\n","    \"\"\"Applies mask to values then returns overall average (a scalar)\n","\n","    Args:\n","      values: a list length max_dec_steps containing arrays shape (batch_size).\n","      padding_mask: tensor shape (batch_size, max_dec_steps) containing 1s and 0s.\n","\n","    Returns:\n","      a scalar\n","    \"\"\"\n","    padding_mask = tf.cast(padding_mask, dtype=values[0].dtype)\n","    dec_lens = tf.reduce_sum(padding_mask, axis=1)  # shape batch_size. float32\n","    values_per_step = [v * padding_mask[:, dec_step] for dec_step, v in enumerate(values)]\n","    values_per_ex = sum(values_per_step) / dec_lens  # shape (batch_size); normalized value for each batch member\n","    return tf.reduce_mean(values_per_ex)  # overall average\n","\n","\n","def _coverage_loss(attn_dists, padding_mask):\n","    \"\"\"Calculates the coverage loss from the attention distributions.\n","\n","    Args:\n","      attn_dists: The attention distributions for each decoder timestep. A list length max_dec_steps containing shape (batch_size, attn_length)\n","      padding_mask: shape (batch_size, max_dec_steps).\n","\n","    Returns:\n","      coverage_loss: scalar\n","    \"\"\"\n","    coverage = tf.zeros_like(attn_dists[0])  # shape (batch_size, attn_length). Initial coverage is zero.\n","    covlosses = []  # Coverage loss per decoder timestep. Will be list length max_dec_steps containing shape (batch_size).\n","    for a in attn_dists:\n","        covloss = tf.reduce_sum(tf.minimum(a, coverage), [1])  # calculate the coverage loss for this step\n","        covlosses.append(covloss)\n","        coverage += a  # update the coverage vector\n","    coverage_loss = _mask_and_avg(covlosses, padding_mask)\n","    return coverage_loss\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kj6jMkdY74wW","colab_type":"code","colab":{}},"source":["\n","\n","class UnidirGruEncoder(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, word_matrix, enc_units, batch_sz):\n","    super(UnidirGruEncoder, self).__init__()\n","    self.batch_sz = batch_sz\n","    self.enc_units = enc_units\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, weights = [word_matrix], trainable=False)\n","    self.gru = tf.keras.layers.GRU(self.enc_units,\n","            return_sequences=True,\n","            return_state=True,\n","            recurrent_initializer='glorot_uniform')\n","    \n","  def initialize_hidden_state(self, batch_size = 0):\n","    if batch_size == 0:\n","      batch_size = self.batch_sz\n","    return tf.zeros((batch_size, self.enc_units))\n","\n","  def call(self, x, hidden):\n","    x = self.embedding(x)\n","    \n","    output, state = self.gru(x, initial_state = hidden)\n","    \n","    return output, state\n","\n","\n","# TODO: Add bais for it\n","class BahdanauAttention(tf.keras.Model):\n","  def __init__(self, units):\n","    super(BahdanauAttention, self).__init__()\n","    self.W1 = tf.keras.layers.Dense(units)\n","    self.W2 = tf.keras.layers.Dense(units)\n","    self.Wc = tf.keras.layers.Dense(units) # this is for coverage\n","    self.V = tf.keras.layers.Dense(1)\n","\n","  def call(self, query, values, use_coverage, prev_coverage=None):\n","    # we are doing this to perform addition to calculate the score\n","    hidden_with_time_axis = tf.expand_dims(query, 1)\n","\n","    # we get 1 at the last axis because we are applying score to self.V\n","    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n","    w1 = self.W1(values)\n","\n","    w2 = self.W2(hidden_with_time_axis)\n","\n","    sum_w12 = w1 + w2\n","\n","    if use_coverage and prev_coverage is not None:\n","      wc = self.Wc(prev_coverage)\n","      sum_w12 += wc\n","\n","    aw12 = tf.nn.tanh(sum_w12)\n","\n","    score = self.V(aw12)\n","\n","    # attention_weights shape == (batch_size, max_length, 1)\n","    attention_weights = tf.nn.softmax(score, axis=1)\n","\n","    # context_vector shape after sum == (batch_size, hidden_size)\n","    context_vector = attention_weights * values\n","\n","    context_vector = tf.reduce_sum(context_vector, axis=1)\n","\n","    if use_coverage and prev_coverage is not None:\n","      coverage = attention_weights\n","    else:\n","      coverage = None\n","\n","    return context_vector, attention_weights, coverage\n","\n","\n","class UniGruDecoderWithAttention(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, word_matrix, dec_units, batch_sz):\n","    super(UniGruDecoderWithAttention, self).__init__()\n","    self.batch_sz = batch_sz\n","    self.dec_units = dec_units\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, weights = [word_matrix], trainable=False)\n","    self.gru = tf.keras.layers.GRU(self.dec_units,\n","                                   return_sequences=True,\n","                                   return_state=True,\n","                                   recurrent_initializer='glorot_uniform')\n","    self.fc = tf.keras.layers.Dense(vocab_size, activation=tf.keras.activations.softmax)\n","\n","    # used for attention\n","    # self.attention = BahdanauAttention(self.dec_units)\n","\n","  def call(self, x, hidden, enc_output, context_vector):\n","    # enc_output shape == (batch_size, max_length, hidden_size)\n","    # context_vector, attention_weights = self.attention(hidden, enc_output)\n","\n","    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n","    x = self.embedding(x)\n","\n","    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n","    context_vector = tf.expand_dims(context_vector, 1)\n","\n","    x = tf.concat([context_vector, x], axis=-1)\n","\n","    # passing the concatenated vector to the GRU\n","    output, state = self.gru(x)\n","\n","    # output shape == (batch_size * 1, hidden_size)\n","    output = tf.reshape(output, (-1, output.shape[2]))\n","\n","    # output shape == (batch_size, vocab)\n","    prediction = self.fc(output)\n","\n","    return x, prediction, state\n","\n","class Pointer(tf.keras.layers.Layer):\n","  def __init__(self):\n","    super(Pointer, self).__init__()\n","    self.w_s_reduce = tf.keras.layers.Dense(1)\n","    self.w_i_reduce = tf.keras.layers.Dense(1)\n","    self.w_c_reduce = tf.keras.layers.Dense(1)\n","\n","  def __call__(self, context_vector, dec_hidden, dec_inp):\n","    return tf.nn.sigmoid(self.w_s_reduce(dec_hidden) + self.w_c_reduce(context_vector) + self.w_i_reduce(dec_inp))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bpp3MLBfnH-e","colab_type":"code","colab":{}},"source":["\n","class PGN(tf.keras.Model):\n","  def __init__(self, params):\n","    super(PGN, self).__init__()\n","    self.working_ds = AutoCarDataSet()\n","    self.working_ds.prepare_data(force_build=False)\n","    self.working_ds.get_wv_model(force_build=False)\n","\n","    # define constants for codec\n","    self.BUFFER_SIZE = self.working_ds.train_ids_x.shape[0]\n","    self.BATCH_SIZE = 16\n","    self.steps_per_epoch = self.working_ds.train_ids_x.shape[0]//self.BATCH_SIZE\n","    self.embedding_dim = wv_embedding_dim\n","    self.codec_units = 256\n","    self.vocab_inp_size = len(self.working_ds.vocab)\n","    self.vocab_tar_size = self.vocab_inp_size\n","\n","    self.checkpoint_dir = os.path.join(checkpoint_dir_tf, 'unigru_attn_pgn')\n","    self.checkpoint_prefix = os.path.join(self.checkpoint_dir, \"ckpt\")\n","\n","    # self.optimizer = tf.keras.optimizers.Adam(1e-3)\n","    self.optimizer = tf.keras.optimizers.Adagrad(1e-3, \n","                initial_accumulator_value=0.1, clipnorm=2.0)\n","\n","    self.loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n","\n","    self.encoder, self.decoder = self.create_codec()\n","\n","    self.checkpoint = self.def_checkpoint()\n","\n","    self.dataset = self.get_dataset()\n","\n","    self.padding_index = self.working_ds.token_id_pad\n","\n","    self.beam_size = 2\n","\n","    self.use_pgn = True\n","\n","    self.use_coverage = True\n","    self.cov_loss_wt = 0.1\n","\n","    self.encoder, self.decoder = self.create_codec()\n","\n","    self.attention = BahdanauAttention(params[self.codec_units])\n","\n","    self.pointer = Pointer()\n","  \n","  def create_codec(self):\n","    encoder = UnidirGruEncoder(self.vocab_inp_size, self.embedding_dim, self.working_ds.embedding_matrix, self.codec_units, self.BATCH_SIZE)\n","    decoder = UniGruDecoderWithAttention(self.vocab_tar_size, self.embedding_dim, self.working_ds.embedding_matrix, self.codec_units, self.BATCH_SIZE)\n","    return encoder, decoder\n","\n","  def call_encoder(self, enc_inp):\n","    enc_hidden = self.encoder.initialize_hidden_state()\n","    enc_output, enc_hidden = self.encoder(enc_inp, enc_hidden)\n","    return enc_output, enc_hidden\n","\n","  def call_decoder_one_step(self, dec_input, dec_hidden, enc_output, enc_extended_inp, \n","                batch_oov_len, enc_pad_mask, use_coverage, prev_coverage):\n","\n","    context_vector, attentions, coverage_ret = self.attention(dec_hidden, enc_pad_mask, use_coverage, prev_coverage)\n","\n","    dec_x, pred, dec_hidden = self.decoder(dec_input, dec_hidden, enc_output, context_vector)\n","\n","    if self.use_pgn:\n","      p_gen = self.pointer(context_vector, dec_hidden, tf.squeeze(dec_x, axis=1))\n","\n","      final_dists = _calc_final_dist(enc_extended_inp, [pred], [attentions], [p_gen],\n","                       batch_oov_len, self.vocab_inp_size, self.BATCH_SIZE)\n","      \n","      return tf.stack(final_dists, 1), dec_hidden, context_vector, attentions, p_gen, coverage_ret\n","    else:\n","      return pred, dec_hidden, context_vector, attentions, None, coverage_ret\n","\n","  def call(self, enc_inp, dec_inp,\n","       enc_extended_inp, batch_oov_len,\n","       enc_pad_mask, use_coverage, prev_coverage=None):\n","    '''\n","    :param enc_inp:\n","    :param dec_inp:  tf.expand_dims(dec_inp[:, t], 1)\n","    :param enc_extended_inp:\n","    :param batch_oov_len:\n","    '''\n","    predictions = []\n","    attentions = []\n","    p_gens = []\n","    coverages = []\n","\n","    # encoder\n","    enc_output, enc_hidden = self.call_encoder(enc_inp)\n","\n","    dec_hidden = enc_hidden\n","\n","    context_vector, _, coverage_ret = self.attention(dec_hidden,\n","                             enc_output,\n","                             enc_pad_mask,\n","                             use_coverage,\n","                             prev_coverage)\n","    for t in range(dec_inp.shape[1]):\n","      # decoder\n","      # using teacher forcing\n","      dec_x, dec_pred, dec_hidden = self.decoder(tf.expand_dims(dec_inp[:, t], 1),\n","                             dec_hidden,\n","                             enc_output,\n","                             context_vector)\n","\n","      context_vector, attn, coverage_ret = self.attention(dec_hidden,\n","                                enc_output,\n","                                enc_pad_mask,\n","                                use_coverage,\n","                                coverage_ret)\n","\n","      p_gen = self.pointer(context_vector, dec_hidden, tf.squeeze(dec_x, axis=1))\n","      coverages.append(coverage_ret)\n","      attentions.append(attn)\n","      predictions.append(dec_pred)\n","      p_gens.append(p_gen)\n","\n","    if self.use_pgn:\n","      final_dists = self._calc_final_dist(enc_extended_inp,\n","                       predictions,\n","                       attentions,\n","                       p_gens,\n","                       batch_oov_len,\n","                       self.vocab_inp_size,\n","                       self.BATCH_SIZE)\n","      return tf.stack(final_dists, 1), dec_hidden, attentions, tf.stack(p_gens, 1), None\n","    else:\n","      return tf.stack(predictions, 1), dec_hidden, attentions, None, None\n","\n","\n","  def _calc_final_dist(_enc_batch_extend_vocab, vocab_dists, attn_dists, p_gens, batch_oov_len, vocab_size, batch_size):\n","    \"\"\"\n","    Calculate the final distribution, for the pointer-generator model\n","    Args:\n","    vocab_dists: The vocabulary distributions. List length max_dec_steps of (batch_size, vsize) arrays.\n","                The words are in the order they appear in the vocabulary file.\n","    attn_dists: The attention distributions. List length max_dec_steps of (batch_size, attn_len) arrays\n","    Returns:\n","    final_dists: The final distributions. List length max_dec_steps of (batch_size, extended_vsize) arrays.\n","    \"\"\"\n","    # Multiply vocab dists by p_gen and attention dists by (1-p_gen)\n","    vocab_dists = [p_gen * dist for (p_gen, dist) in zip(p_gens, vocab_dists)]\n","    attn_dists = [(1 - p_gen) * dist for (p_gen, dist) in zip(p_gens, attn_dists)]\n","\n","    # Concatenate some zeros to each vocabulary dist, to hold the probabilities for in-article OOV words\n","    extended_vsize = vocab_size + batch_oov_len  # the maximum (over the batch) size of the extended vocabulary\n","    extra_zeros = tf.zeros((batch_size, batch_oov_len))\n","    # list length max_dec_steps of shape (batch_size, extended_vsize)\n","    vocab_dists_extended = [tf.concat(axis=1, values=[dist, extra_zeros]) for dist in vocab_dists]\n","\n","    # Project the values in the attention distributions onto the appropriate entries in the final distributions\n","    # This means that if a_i = 0.1 and the ith encoder word is w, and w has index 500 in the vocabulary,\n","    # then we add 0.1 onto the 500th entry of the final distribution\n","    # This is done for each decoder timestep.\n","    # This is fiddly; we use tf.scatter_nd to do the projection\n","    batch_nums = tf.range(0, limit=batch_size)  # shape (batch_size)\n","    batch_nums = tf.expand_dims(batch_nums, 1)  # shape (batch_size, 1)\n","    attn_len = tf.shape(_enc_batch_extend_vocab)[1]  # number of states we attend over\n","    batch_nums = tf.tile(batch_nums, [1, attn_len])  # shape (batch_size, attn_len)\n","    indices = tf.stack((batch_nums, _enc_batch_extend_vocab), axis=2)  # shape (batch_size, enc_t, 2)\n","    shape = [batch_size, extended_vsize]\n","    # list length max_dec_steps (batch_size, extended_vsize)\n","    attn_dists_projected = [tf.scatter_nd(indices, copy_dist, shape) for copy_dist in attn_dists]\n","\n","    # Add the vocab distributions and the copy distributions together to get the final distributions\n","    # final_dists is a list length max_dec_steps; each entry is a tensor shape (batch_size, extended_vsize) giving\n","    # the final distribution for that decoder timestep\n","    # Note that for decoder timesteps and examples corresponding to a [PAD] token, this is junk - ignore.\n","    final_dists = [vocab_dist + copy_dist for (vocab_dist, copy_dist) in\n","                   zip(vocab_dists_extended, attn_dists_projected)]\n","\n","    return final_dists\n","\n","  def train_step(self, enc_inp, extended_enc_input, max_oov_len,\n","           dec_input, dec_target,\n","           enc_pad_mask, padding_mask):\n","    # print('************train_step*************')\n","    with tf.GradientTape() as tape:\n","      # 逐个预测序列\n","\n","      final_dists, _, attentions, p_gen, coverages = self.call(enc_inp,\n","                                 dec_input,\n","                                 extended_enc_input,\n","                                 max_oov_len,\n","                                 enc_pad_mask=enc_pad_mask,\n","                                 use_coverage=self.use_coverage,\n","                                 prev_coverage=None)\n","\n","      batch_loss, log_loss, cov_loss = calc_loss(dec_target, final_dists, padding_mask, attentions,\n","                             self.cov_loss_wt, self.use_coverage)\n","\n","    # print('************variables*************')\n","    variables = self.encoder.trainable_variables + self.decoder.trainable_variables + \\\n","          self.attention.trainable_variables + self.pointer.trainable_variables\n","\n","    # print('************gradient*************')\n","    gradients = tape.gradient(batch_loss, variables)\n","\n","    # print('************optimizer*************')\n","    optimizer.apply_gradients(zip(gradients, variables))\n","\n","    return batch_loss, log_loss, cov_loss\n","\n","  def train_one_batch(self, encoder, decoder, inp, targ, enc_hidden):\n","    return train_step(self, enc_inp, extended_enc_input, max_oov_len,\n","           dec_input, dec_target, enc_pad_mask, padding_mask)\n","\n","  def train_one_epoch(self, encoder, decoder, dataset):\n","      enc_hidden = encoder.initialize_hidden_state()\n","      total_loss = 0.0\n","\n","      starttime = time.time()\n","      print('Epoch start time {}'.format(starttime))\n","      loss_history = []\n","      for (batch, (inp, targ)) in enumerate(dataset.take(self.steps_per_epoch)):\n","          batch_loss = self.train_one_batch(encoder, decoder, inp, targ, enc_hidden)\n","          total_loss += batch_loss\n","\n","          loss_history.append(batch_loss)\n","\n","          # if batch == 5:\n","          #   break\n","\n","          if (batch+1) % 100 == 0:\n","              # print('Batch {} time {:.2f}'.format(batch, time.time() - starttime))\n","              print('Batch {} Loss {:.4f} time {:.2f}'.format(batch+1, batch_loss.numpy(), time.time() - starttime)) #Not valid if @tf.function\n","      print('Loss at epoch end {:.4f}'.format(total_loss / self.steps_per_epoch)) #Not valid if @tf.function\n","\n","      return total_loss / self.steps_per_epoch\n","\n","  def def_checkpoint(self):\n","      checkpoint = tf.train.Checkpoint(seq2seq=self)\n","      return checkpoint\n","\n","  def create_codec(self):\n","      encoder = UnidirGruEncoder(self.vocab_inp_size, self.embedding_dim, self.working_ds.embedding_matrix, self.codec_units, self.BATCH_SIZE)\n","      decoder = UniGruDecoderWithAttention(self.vocab_tar_size, self.embedding_dim, self.working_ds.embedding_matrix, self.codec_units, self.BATCH_SIZE)\n","      return encoder, decoder\n","\n","  def get_dataset(self):\n","      dataset = tf.data.Dataset.from_tensor_slices((self.working_ds.train_ids_x, self.working_ds.train_ids_y)).shuffle(self.BUFFER_SIZE)\n","      dataset = dataset.batch(self.BATCH_SIZE, drop_remainder=True)\n","      return dataset\n","\n","  def train_all(self, encoder, decoder, dataset, epochs, save_chkpnts):\n","\n","      loss_history = []\n","      for e in range(epochs):\n","          print('Epoch {} ============================>'.format(e))\n","          epoch_loss = self.train_one_epoch(encoder, decoder, dataset)\n","          loss_history.append(epoch_loss)\n","          \n","          if save_chkpnts  and (e + 1) % 1 == 0:\n","              # saving (checkpoint) the model every 2 epochs\n","              self.checkpoint.save(file_prefix = self.checkpoint_prefix)\n","\n","      return loss_history\n","\n","  def train(self, epochs = 1, save_chkpnts = True):\n","    loss_history = self.train_all(self.encoder, self.decoder, self.dataset, epochs, save_chkpnts)\n","    self.encoder.summary()\n","    self.decoder.summary()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uNc4tU4ex4-w","colab_type":"code","outputId":"72db7103-41eb-40ba-e585-4412416daf7c","executionInfo":{"status":"ok","timestamp":1577350634777,"user_tz":-480,"elapsed":65043,"user":{"displayName":"Luo Yongliang","photoUrl":"","userId":"08228183385143629193"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["\n","class Seq2Seq(tf.keras.Model):\n","  def __init__(self):\n","    super(Seq2Seq, self).__init__()\n","    self.working_ds = AutoCarDataSet()\n","    self.working_ds.prepare_data(force_build=False)\n","    self.working_ds.get_wv_model(force_build=False)\n","\n","    # define constants for codec\n","    self.BUFFER_SIZE = self.working_ds.train_ids_x.shape[0]\n","    self.BATCH_SIZE = 16\n","    self.steps_per_epoch = self.working_ds.train_ids_x.shape[0]//self.BATCH_SIZE\n","    self.embedding_dim = wv_embedding_dim\n","    self.codec_units = 256\n","    self.vocab_inp_size = len(self.working_ds.vocab)\n","    self.vocab_tar_size = len(self.working_ds.vocab)\n","\n","    self.checkpoint_dir = os.path.join(checkpoint_dir_tf, 'unigru_attn')\n","    self.checkpoint_prefix = os.path.join(self.checkpoint_dir, \"ckpt\")\n","\n","    self.optimizer = tf.keras.optimizers.Adam(1e-3)\n","\n","    self.loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n","\n","    self.encoder, self.decoder = self.create_codec()\n","\n","    self.checkpoint = self.def_checkpoint()\n","\n","    self.dataset = self.get_dataset()\n","\n","    self.padding_index = self.working_ds.token_id_pad\n","\n","    self.beam_size = 2\n","\n","  def loss_function(self, real, pred):\n","      mask = tf.math.logical_not(tf.math.equal(real, self.padding_index))\n","\n","      loss_ = self.loss_object(real, pred)\n","\n","      mask = tf.cast(mask, dtype=loss_.dtype)\n","      loss_ *= mask\n","\n","      return tf.reduce_mean(loss_)\n","\n","  def train_one_batch(self, encoder, decoder, inp, targ, enc_hidden):\n","    loss = 0\n","\n","    with tf.GradientTape() as tape:\n","      # print('enc_hidden1: ', enc_hidden)\n","      enc_output, enc_hidden = encoder(inp, enc_hidden)\n","\n","      dec_hidden = enc_hidden\n","\n","      dec_input = tf.expand_dims([self.working_ds.token_id_start] * self.BATCH_SIZE, 1)\n","\n","      # Teacher forcing - feeding the target as the next input\n","      for t in range(1, targ.shape[1]):\n","        # passing enc_output to the decoder\n","        predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n","\n","        loss += self.loss_function(targ[:, t], predictions)\n","\n","        # using teacher forcing\n","        dec_input = tf.expand_dims(targ[:, t], 1)\n","\n","    batch_loss = (loss / int(targ.shape[1]))\n","\n","    variables = encoder.trainable_variables + decoder.trainable_variables\n","\n","    gradients = tape.gradient(loss, variables)\n","\n","    zipped_variables = zip(gradients, variables)\n","\n","    self.optimizer.apply_gradients(zipped_variables)\n","\n","    return batch_loss\n","\n","  def train_one_epoch(self, encoder, decoder, dataset):\n","      enc_hidden = encoder.initialize_hidden_state()\n","      total_loss = 0.0\n","\n","      starttime = time.time()\n","      print('Epoch start time {}'.format(starttime))\n","      loss_history = []\n","      for (batch, (inp, targ)) in enumerate(dataset.take(self.steps_per_epoch)):\n","          batch_loss = self.train_one_batch(encoder, decoder, inp, targ, enc_hidden)\n","          total_loss += batch_loss\n","\n","          loss_history.append(batch_loss)\n","\n","          # if batch == 5:\n","          #   break\n","\n","          if (batch+1) % 100 == 0:\n","              # print('Batch {} time {:.2f}'.format(batch, time.time() - starttime))\n","              print('Batch {} Loss {:.4f} time {:.2f}'.format(batch+1, batch_loss.numpy(), time.time() - starttime)) #Not valid if @tf.function\n","      print('Loss at epoch end {:.4f}'.format(total_loss / self.steps_per_epoch)) #Not valid if @tf.function\n","\n","      return total_loss / self.steps_per_epoch\n","\n","  def def_checkpoint(self):\n","      checkpoint = tf.train.Checkpoint(seq2seq=self)\n","      return checkpoint\n","\n","  def create_codec(self):\n","      encoder = UnidirGruEncoder(self.vocab_inp_size, self.embedding_dim, self.working_ds.embedding_matrix, self.codec_units, self.BATCH_SIZE)\n","      decoder = UniGruDecoderWithAttention(self.vocab_tar_size, self.embedding_dim, self.working_ds.embedding_matrix, self.codec_units, self.BATCH_SIZE)\n","      return encoder, decoder\n","\n","  def get_dataset(self):\n","      dataset = tf.data.Dataset.from_tensor_slices((self.working_ds.train_ids_x, self.working_ds.train_ids_y)).shuffle(self.BUFFER_SIZE)\n","      dataset = dataset.batch(self.BATCH_SIZE, drop_remainder=True)\n","      return dataset\n","\n","  def train_all(self, encoder, decoder, dataset, epochs, save_chkpnts):\n","\n","      loss_history = []\n","      for e in range(epochs):\n","          print('Epoch {} ============================>'.format(e))\n","          epoch_loss = self.train_one_epoch(encoder, decoder, dataset)\n","          loss_history.append(epoch_loss)\n","          \n","          if save_chkpnts  and (e + 1) % 1 == 0:\n","              # saving (checkpoint) the model every 2 epochs\n","              self.checkpoint.save(file_prefix = self.checkpoint_prefix)\n","\n","      return loss_history\n","\n","  def train(self, epochs = 1, save_chkpnts = True):\n","    loss_history = self.train_all(self.encoder, self.decoder, self.dataset, epochs, save_chkpnts)\n","    self.encoder.summary()\n","    self.decoder.summary()\n","\n","  # ====================Below is for beam evalutions====================\n","\n","  def documents_as_tensor(self, docs):\n","    newdocs = []\n","    for i in range(len(docs)):\n","      doc = sentence_proc(docs[i])\n","      doc = pad_proc(doc, self.working_ds.X_max_len, self.working_ds.vocab)\n","      doc = transform_data(doc, self.working_ds.vocab)\n","      newdocs.append(doc)\n","    return tf.convert_to_tensor(newdocs)\n","\n","  #Evaluate in batches\n","  def evaluate_docs(self, encoder, decoder, docs):\n","\n","    inputs = self.documents_as_tensor(docs)\n","\n","    attention_plot = np.zeros((inputs.shape[0], self.working_ds.train_y_max_len, self.working_ds.X_max_len))\n","\n","    result = [[self.working_ds.token_id_start] for _ in range(inputs.shape[0])]\n","\n","    hidden = self.encoder.initialize_hidden_state(batch_size = inputs.shape[0])\n","    enc_out, enc_hidden = encoder(inputs, hidden)\n","\n","    dec_hidden = enc_hidden\n","\n","    start_id = self.working_ds.token_id_start\n","    dec_input = tf.dtypes.cast(tf.convert_to_tensor((np.ones((inputs.shape[0], 1))*start_id)), tf.int32)\n","\n","    stop_flags = np.zeros((inputs.shape[0])).astype(bool)\n","    # pdb.set_trace()\n","    for t in range(self.working_ds.train_y_max_len):\n","        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n","\n","        dec_input = np.zeros((inputs.shape[0], 1))\n","        for i in range(inputs.shape[0]):\n","          if not stop_flags[i]:\n","            # storing the attention weights to plot later on\n","            attention_weight = tf.reshape(attention_weights[i], (-1,))\n","            attention_plot[i][t] = attention_weight.numpy()\n","\n","            predicted_id = tf.argmax(predictions[i]).numpy()\n","\n","            result[i].append(predicted_id)\n","\n","            if predicted_id == self.working_ds.token_id_stop:\n","              stop_flags[i] = True\n","\n","            # the predicted ID is fed back into the model\n","            dec_input[i][0] = predicted_id\n","\n","        dec_input = tf.dtypes.cast(tf.convert_to_tensor(dec_input), tf.int32)\n","\n","        if stop_flags.all():\n","          break\n","\n","    return result, inputs, attention_plot\n","\n","  def train_one_batch_only(self, encoder, decoder, dataset):\n","    enc_hidden = encoder.initialize_hidden_state()\n","\n","    inp, targ = next(iter(dataset))\n","    batch_loss = self.train_one_batch(encoder, decoder, inp, targ, enc_hidden)\n","\n","    return batch_loss\n","\n","  def train_one_batch_and_restore_from_checkpoint(self):\n","    self.train_one_batch_only(self.encoder, self.decoder, self.dataset)\n","    load_status = self.checkpoint.restore(tf.train.latest_checkpoint(self.checkpoint_dir))\n","    load_status.assert_consumed()\n","    print('Succesfully restored from: ', self.checkpoint_dir)\n","    print(tf.train.latest_checkpoint(self.checkpoint_dir))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Building prefix dict from the default dictionary ...\n","2019-12-26 08:57:11,991 : DEBUG : Building prefix dict from the default dictionary ...\n","Dumping model to file cache /tmp/jieba.cache\n","2019-12-26 08:57:12,650 : DEBUG : Dumping model to file cache /tmp/jieba.cache\n","Loading model cost 0.718 seconds.\n","2019-12-26 08:57:12,714 : DEBUG : Loading model cost 0.718 seconds.\n","Prefix dict has been built succesfully.\n","2019-12-26 08:57:12,719 : DEBUG : Prefix dict has been built succesfully.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"VvcR3LjqiwKW","colab_type":"text"},"source":["# 这里是上下分隔符，下面都是测试代码======================="]},{"cell_type":"code","metadata":{"id":"UGgo9hRd3lvk","colab_type":"code","colab":{}},"source":["ss.train(epochs = 5, save_chkpnts = False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a7TbVUilHNmL","colab_type":"code","cellView":"both","outputId":"fb496893-c982-4af7-b65d-df71aab2b921","executionInfo":{"status":"ok","timestamp":1577351466897,"user_tz":-480,"elapsed":21479,"user":{"displayName":"Luo Yongliang","photoUrl":"","userId":"08228183385143629193"}},"colab":{"base_uri":"https://localhost:8080/","height":241}},"source":["#@title\n","ss = Seq2Seq()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["File read:  /gdrive/My Drive/python-code/文本摘要-01/data/train_seg_data.csv /gdrive/My Drive/python-code/文本摘要-01/data/test_seg_data.csv\n","sentences_proced train data size 82823,test data size 20000\n"],"name":"stdout"},{"output_type":"stream","text":["2019-12-26 09:10:49,436 : INFO : loading Word2Vec object from /gdrive/My Drive/python-code/文本摘要-01/data/wv/word2vec.model\n"],"name":"stderr"},{"output_type":"stream","text":["File read:  /gdrive/My Drive/python-code/文本摘要-01/data/merged_train_test_seg_data.csv\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n","2019-12-26 09:10:50,177 : INFO : loading wv recursively from /gdrive/My Drive/python-code/文本摘要-01/data/wv/word2vec.model.wv.* with mmap=None\n","2019-12-26 09:10:50,178 : INFO : setting ignored attribute vectors_norm to None\n","2019-12-26 09:10:50,178 : INFO : loading vocabulary recursively from /gdrive/My Drive/python-code/文本摘要-01/data/wv/word2vec.model.vocabulary.* with mmap=None\n","2019-12-26 09:10:50,179 : INFO : loading trainables recursively from /gdrive/My Drive/python-code/文本摘要-01/data/wv/word2vec.model.trainables.* with mmap=None\n","2019-12-26 09:10:50,180 : INFO : setting ignored attribute cum_table to None\n","2019-12-26 09:10:50,181 : INFO : loaded /gdrive/My Drive/python-code/文本摘要-01/data/wv/word2vec.model\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"_gI_k1FnY6Ya","colab_type":"code","outputId":"28c5278d-ce24-475a-c371-76fe91c856b1","executionInfo":{"status":"ok","timestamp":1577350807443,"user_tz":-480,"elapsed":770,"user":{"displayName":"Luo Yongliang","photoUrl":"","userId":"08228183385143629193"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["ss.train_one_batch_and_restore_from_checkpoint()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Succesfully restored from:  /gdrive/My Drive/python-code/文本摘要-01/checkpoints/tf/unigru_attn\n","/gdrive/My Drive/python-code/文本摘要-01/checkpoints/tf/unigru_attn/ckpt-15\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"36_Sh_tCbv_k","colab_type":"code","colab":{}},"source":["train_df = pd.read_csv(train_data_path )\n","test_df = pd.read_csv(test_data_path )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iRYzdfrBc36N","colab_type":"code","outputId":"4f476d1e-850b-4adb-9f0a-a847511091ad","executionInfo":{"status":"error","timestamp":1577351231422,"user_tz":-480,"elapsed":27164,"user":{"displayName":"Luo Yongliang","photoUrl":"","userId":"08228183385143629193"}},"colab":{"base_uri":"https://localhost:8080/","height":461}},"source":["from datetime import datetime, date\n","\n","def automaster_test_reader(batch_size, test_df):\n","  for idx in range(0, test_df.shape[0], batch_size):\n","    docs = []\n","    idxs = []\n","    for i in range(idx, idx + batch_size):\n","      if i >= test_df.shape[0]:\n","        break\n","      doc = ' '.join([test_df['Question'].iloc[i], test_df['Dialogue'].iloc[i]])\n","      docs.append(doc)\n","      idxs.append(i)\n","    yield idxs, docs\n","\n","def evaluate_all_test_attn():\n","  # pdb.set_trace()\n","  result_path = os.path.join(save_result_dir, 'tf', 'unigru-attn', 'result-unigru-attn' + str(date.today()) + '-' + datetime.now().strftime(\"%H-%M-%S\") + '.csv')\n","  print(result_path)\n","\n","  test_batch_size = 64\n","  starttime = time.time()\n","  with open(result_path, mode='wt') as f:\n","    f.write('QID,Prediction\\n')\n","    batch_count = 0\n","    for idxs, docs in automaster_test_reader(test_batch_size, test_df):\n","      (result, inputs, attention_plot) = ss.evaluate_docs(ss.encoder, ss.decoder, docs)\n","\n","      for i in range(len(result)):\n","        res_str = test_df['QID'].iloc[idxs[i]] + ',' + ss.working_ds.tokens_to_texts(result[i]).replace(' ', '') + '\\n'\n","        f.write(res_str)\n","      \n","      batch_count += 1\n","\n","      if (batch_count * test_batch_size) % 128 == 0:\n","        print('processed: {}, at time: {:.2f}'.format(batch_count * test_batch_size, time.time() - starttime ))\n","\n","def evaluate_all_test_beam():\n","  # pdb.set_trace()\n","  result_path = os.path.join(save_result_dir, 'tf', 'unigru-attn-beam', 'result-unigru-attn-beam' + str(date.today()) + '-' + datetime.now().strftime(\"%H-%M-%S\") + '.csv')\n","  print(result_path)\n","\n","  test_batch_size = 1\n","  starttime = time.time()\n","  with open(result_path, mode='wt') as f:\n","    f.write('QID,Prediction\\n')\n","    batch_count = 0\n","    for idxs, docs in automaster_test_reader(test_batch_size, test_df):\n","      result, results = ss.evaluate_beam(ss.encoder, ss.decoder, docs)\n","\n","      res_str = test_df['QID'].iloc[idxs[0]] + ',' + ss.working_ds.tokens_to_texts(result[1:]).replace(' ', '') + '\\n'\n","      f.write(res_str)\n","\n","      batch_count += 1\n","\n","      if (batch_count * test_batch_size) % 32 == 0:\n","        print('processed: {}, at time: {:.2f}'.format(batch_count * test_batch_size, time.time() - starttime ))\n","\n","\n","evaluate_all_test_attn()\n","\n","# idx = 2502\n","# doc = ' '.join([test_df['Question'].iloc[idx], test_df['Dialogue'].iloc[idx]])\n","# # doc = '机油'\n","# print(doc)\n","# # pdb.set_trace()\n","# # (result, inputs, attention_plot) = ss.evaluate(ss.encoder, ss.decoder, doc)\n","# (result, topks) = ss.evaluate_beam(doc)\n","# pdb.set_trace()\n","# print(result)\n","\n","# print(ss.working_ds.tokens_to_texts(result))\n","\n","# print(ss.working_ds.tokens_to_texts(topks[0][1:]))\n","# print(ss.working_ds.tokens_to_texts(topks[1][1:]))\n","# print(ss.working_ds.tokens_to_texts(topks[2][1:]))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/gdrive/My Drive/python-code/文本摘要-01/result/tf/unigru-attn/result-unigru-attn2019-12-26-09-06-45.csv\n","processed: 128, at time: 5.70\n","processed: 256, at time: 10.86\n","processed: 384, at time: 15.61\n","processed: 512, at time: 21.07\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-48c92ee61568>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mevaluate_all_test_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# idx = 2502\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-48c92ee61568>\u001b[0m in \u001b[0;36mevaluate_all_test_attn\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mbatch_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mautomaster_test_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m       \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_plot\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_docs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-6c24f338f708>\u001b[0m in \u001b[0;36mevaluate_docs\u001b[0;34m(self, encoder, decoder, docs)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mattention_plot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0mpredicted_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m     \"\"\"\n\u001b[1;32m    941\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"P2gH8Jqr7dGm","colab_type":"code","outputId":"5d8f1cc7-af16-470f-aa7c-5b20c277ab3f","executionInfo":{"status":"ok","timestamp":1577157786840,"user_tz":-480,"elapsed":1416,"user":{"displayName":"Luo Yongliang","photoUrl":"","userId":"08228183385143629193"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["tf.expand_dims([ss.working_ds.vocab['<START>']], 0)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[31810]], dtype=int32)>"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"jTfllqWfIFKe","colab_type":"code","colab":{}},"source":["print(ss.encoder.trainable_variables)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6uD5KUf1Rv7B","colab_type":"code","outputId":"8e44de3b-179b-4a45-dba2-f424d2a60a02","executionInfo":{"status":"ok","timestamp":1576944853766,"user_tz":-480,"elapsed":3918,"user":{"displayName":"Luo Yongliang","photoUrl":"","userId":"08228183385143629193"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["ss.checkpoint.save_counter"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Variable 'save_counter:0' shape=() dtype=int64, numpy=2>"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"QAulDhEDBkr9","colab_type":"code","colab":{}},"source":["docs = []\n","idx = 2502\n","for i in range(idx, idx+4):\n","  doc = ' '.join([test_df['Question'].iloc[i], test_df['Dialogue'].iloc[i]])\n","  docs.append(doc)\n","# doc = '机油'\n","print(docs)\n","# pdb.set_trace()\n","# (result, inputs, attention_plot) = ss.evaluate(ss.encoder, ss.decoder, doc)\n","(result, inputs, attention_plot) = ss.evaluate_docs(ss.encoder, ss.decoder, docs)\n","for r in result:\n","  print(r)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XdqcImd2Im-1","colab_type":"code","outputId":"e12c8c54-2034-4089-d32d-56b681a58880","executionInfo":{"status":"ok","timestamp":1577161295722,"user_tz":-480,"elapsed":1610,"user":{"displayName":"Luo Yongliang","photoUrl":"","userId":"08228183385143629193"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(result[3])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["不 超过 80 码 ， 车速 不要 超过 80 码 ， 车速 不要 超过 80 码 ， 车速 不要 超过 80 码 ， 车速 不要 超过 80 码 ， 车速 不要 超过 80 码 ， 车速 不要 超过 80 \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xdb5P91ab6lA","colab_type":"code","outputId":"bedbbb5b-775e-4a15-bcce-7b7fafe00fbb","executionInfo":{"status":"ok","timestamp":1577160202915,"user_tz":-480,"elapsed":1334,"user":{"displayName":"Luo Yongliang","photoUrl":"","userId":"08228183385143629193"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["idx = 2502\n","doc = ' '.join([test_df['Question'].iloc[idx], test_df['Dialogue'].iloc[idx]])\n","# doc = '机油'\n","print(doc)\n","# pdb.set_trace()\n","# (result, inputs, attention_plot) = ss.evaluate(ss.encoder, ss.decoder, doc)\n","(result, inputs, attention_plot) = ss.evaluate(ss.encoder, ss.decoder, doc)\n","print(result)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["福特翼虎1.6T更换正时皮带，因为没有专用工具，想知道怎么精确找出曲轴1缸上支点，怎么固定？凸轮轴我对的末端的卡槽这样会有问题吗？急！急！急！ 技师说：您好，需要使用专用工具装配。曲轴的位置需要一个专用螺丝拧进去，然后顶住曲轴的位置就可以了。|技师说：凸轮轴后面的卡槽需要与缸盖的平面边缘平齐就可以了。|车主说：这车的变速箱油得加多少升？没有用机器，直接放的没有起车排油，|技师说：如果采用重力更换需要五升。\n","需要 使用 专用工具 安装 。 专用工具 ， 需要 专用工具 ， 需要 专用工具 ， 需要 专用工具 ， 需要 专用工具 ， 需要 专用工具 ， 需要 专用工具 ， 需要 专用工具 ， 需要 专用工具 ， 需要 专用工具 ， 需要 专用工具 ， 需要 专用工具 \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d4DA94pvI-ja","colab_type":"code","outputId":"a0414d3d-bf67-4417-e9ed-466b08362394","executionInfo":{"status":"ok","timestamp":1577163475475,"user_tz":-480,"elapsed":1559259,"user":{"displayName":"Luo Yongliang","photoUrl":"","userId":"08228183385143629193"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from datetime import datetime, date\n","result_path = os.path.join(save_result_dir, 'tf', 'unigru-attn', 'result-' + str(date.today()) + '-' + datetime.now().strftime(\"%H-%M-%S\") + '.csv')\n","print(result_path)\n","\n","eval_batch_size = 64\n","starttime = time.time()\n","with open(result_path, mode='wt') as f:\n","  f.write('QID,Prediction\\n')\n","  for idx in range(0, test_df.shape[0], eval_batch_size):\n","    docs = []\n","    for i in range(idx, idx + eval_batch_size):\n","      if i >= test_df.shape[0]:\n","        break\n","      doc = ' '.join([test_df['Question'].iloc[i], test_df['Dialogue'].iloc[i]])\n","      docs.append(doc)\n","\n","    (result, inputs, attention_plot) = ss.evaluate_docs(ss.encoder, ss.decoder, docs)\n","\n","    for i in range(idx, idx + eval_batch_size):\n","      if i >= test_df.shape[0]:\n","        break\n","      res_str = test_df['QID'].iloc[i] + ',' + result[i - idx].replace(' ', '') + '\\n'\n","      f.write(res_str)\n","\n","    if (idx + 0) % 128 == 0:\n","      print('processed: {}, at time: {:.2f}'.format(idx + 0, time.time() - starttime ))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/gdrive/My Drive/python-code/文本摘要-01/result/tf/unigru-attn/result-2019-12-24-04-31-59.csv\n","processed: 0, at time: 4.92\n","processed: 128, at time: 14.77\n","processed: 256, at time: 24.71\n","processed: 384, at time: 34.64\n","processed: 512, at time: 44.54\n","processed: 640, at time: 54.50\n","processed: 768, at time: 64.74\n","processed: 896, at time: 74.68\n","processed: 1024, at time: 84.59\n","processed: 1152, at time: 94.49\n","processed: 1280, at time: 104.31\n","processed: 1408, at time: 114.27\n","processed: 1536, at time: 124.22\n","processed: 1664, at time: 134.82\n","processed: 1792, at time: 144.83\n","processed: 1920, at time: 154.95\n","processed: 2048, at time: 164.83\n","processed: 2176, at time: 174.85\n","processed: 2304, at time: 184.82\n","processed: 2432, at time: 194.95\n","processed: 2560, at time: 204.88\n","processed: 2688, at time: 214.83\n","processed: 2816, at time: 224.77\n","processed: 2944, at time: 234.81\n","processed: 3072, at time: 244.73\n","processed: 3200, at time: 254.64\n","processed: 3328, at time: 264.60\n","processed: 3456, at time: 274.44\n","processed: 3584, at time: 284.47\n","processed: 3712, at time: 294.38\n","processed: 3840, at time: 304.27\n","processed: 3968, at time: 314.25\n","processed: 4096, at time: 324.15\n","processed: 4224, at time: 334.24\n","processed: 4352, at time: 344.31\n","processed: 4480, at time: 354.16\n","processed: 4608, at time: 364.17\n","processed: 4736, at time: 374.40\n","processed: 4864, at time: 384.30\n","processed: 4992, at time: 394.12\n","processed: 5120, at time: 404.11\n","processed: 5248, at time: 414.09\n","processed: 5376, at time: 424.05\n","processed: 5504, at time: 434.08\n","processed: 5632, at time: 444.81\n","processed: 5760, at time: 454.90\n","processed: 5888, at time: 464.86\n","processed: 6016, at time: 474.88\n","processed: 6144, at time: 484.90\n","processed: 6272, at time: 495.02\n","processed: 6400, at time: 505.07\n","processed: 6528, at time: 515.05\n","processed: 6656, at time: 525.13\n","processed: 6784, at time: 535.06\n","processed: 6912, at time: 544.98\n","processed: 7040, at time: 555.11\n","processed: 7168, at time: 565.17\n","processed: 7296, at time: 575.18\n","processed: 7424, at time: 585.28\n","processed: 7552, at time: 595.32\n","processed: 7680, at time: 605.27\n","processed: 7808, at time: 615.14\n","processed: 7936, at time: 625.22\n","processed: 8064, at time: 635.10\n","processed: 8192, at time: 645.38\n","processed: 8320, at time: 655.37\n","processed: 8448, at time: 665.37\n","processed: 8576, at time: 675.87\n","processed: 8704, at time: 686.02\n","processed: 8832, at time: 696.06\n","processed: 8960, at time: 706.11\n","processed: 9088, at time: 716.16\n","processed: 9216, at time: 726.25\n","processed: 9344, at time: 736.29\n","processed: 9472, at time: 746.35\n","processed: 9600, at time: 756.86\n","processed: 9728, at time: 766.98\n","processed: 9856, at time: 777.04\n","processed: 9984, at time: 787.00\n","processed: 10112, at time: 797.02\n","processed: 10240, at time: 807.02\n","processed: 10368, at time: 816.96\n","processed: 10496, at time: 826.99\n","processed: 10624, at time: 836.98\n","processed: 10752, at time: 846.95\n","processed: 10880, at time: 856.91\n","processed: 11008, at time: 866.74\n","processed: 11136, at time: 876.60\n","processed: 11264, at time: 886.60\n","processed: 11392, at time: 896.48\n","processed: 11520, at time: 906.37\n","processed: 11648, at time: 916.34\n","processed: 11776, at time: 926.18\n","processed: 11904, at time: 936.11\n","processed: 12032, at time: 946.09\n","processed: 12160, at time: 956.01\n","processed: 12288, at time: 965.82\n","processed: 12416, at time: 975.89\n","processed: 12544, at time: 985.97\n","processed: 12672, at time: 995.77\n","processed: 12800, at time: 1005.58\n","processed: 12928, at time: 1015.42\n","processed: 13056, at time: 1025.28\n","processed: 13184, at time: 1035.01\n","processed: 13312, at time: 1044.91\n","processed: 13440, at time: 1054.76\n","processed: 13568, at time: 1065.28\n","processed: 13696, at time: 1075.21\n","processed: 13824, at time: 1084.98\n","processed: 13952, at time: 1094.84\n","processed: 14080, at time: 1104.68\n","processed: 14208, at time: 1114.57\n","processed: 14336, at time: 1124.52\n","processed: 14464, at time: 1134.48\n","processed: 14592, at time: 1144.32\n","processed: 14720, at time: 1154.29\n","processed: 14848, at time: 1164.18\n","processed: 14976, at time: 1173.94\n","processed: 15104, at time: 1183.72\n","processed: 15232, at time: 1193.52\n","processed: 15360, at time: 1203.36\n","processed: 15488, at time: 1213.14\n","processed: 15616, at time: 1223.02\n","processed: 15744, at time: 1232.85\n","processed: 15872, at time: 1242.64\n","processed: 16000, at time: 1252.63\n","processed: 16128, at time: 1262.46\n","processed: 16256, at time: 1272.26\n","processed: 16384, at time: 1282.45\n","processed: 16512, at time: 1292.60\n","processed: 16640, at time: 1302.41\n","processed: 16768, at time: 1312.32\n","processed: 16896, at time: 1322.17\n","processed: 17024, at time: 1332.12\n","processed: 17152, at time: 1341.96\n","processed: 17280, at time: 1351.83\n","processed: 17408, at time: 1361.72\n","processed: 17536, at time: 1372.00\n","processed: 17664, at time: 1382.08\n","processed: 17792, at time: 1391.90\n","processed: 17920, at time: 1401.79\n","processed: 18048, at time: 1411.62\n","processed: 18176, at time: 1421.63\n","processed: 18304, at time: 1431.56\n","processed: 18432, at time: 1441.49\n","processed: 18560, at time: 1451.33\n","processed: 18688, at time: 1461.22\n","processed: 18816, at time: 1471.06\n","processed: 18944, at time: 1480.81\n","processed: 19072, at time: 1490.68\n","processed: 19200, at time: 1500.59\n","processed: 19328, at time: 1510.39\n","processed: 19456, at time: 1520.32\n","processed: 19584, at time: 1530.17\n","processed: 19712, at time: 1540.07\n","processed: 19840, at time: 1550.07\n","processed: 19968, at time: 1557.72\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Du8puzU14YMn","colab_type":"code","outputId":"6aafc052-61fa-46c6-ffa2-06b9030f660f","executionInfo":{"status":"ok","timestamp":1577157124256,"user_tz":-480,"elapsed":1128,"user":{"displayName":"Luo Yongliang","photoUrl":"","userId":"08228183385143629193"}},"colab":{"base_uri":"https://localhost:8080/","height":504}},"source":["attention_plot.resize(39, 50)\n","import matplotlib.pyplot as plt\n","fig = plt.figure(figsize=(10,10))\n","ax = fig.add_subplot(1, 1, 1)\n","ax.matshow(attention_plot, cmap='viridis')\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fc4bbaac0b8>"]},"metadata":{"tags":[]},"execution_count":27},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAlAAAAHWCAYAAAC447cdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAIAhAQUAMCSgAACG/i/eQDsXHkty6wAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 720x720 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"TITrliYJqOdm","colab_type":"code","outputId":"5c10ece0-c301-4d2e-d34f-3f259aee4de8","executionInfo":{"status":"error","timestamp":1577156631600,"user_tz":-480,"elapsed":59306,"user":{"displayName":"Luo Yongliang","photoUrl":"","userId":"08228183385143629193"}},"colab":{"base_uri":"https://localhost:8080/","height":495}},"source":["from datetime import datetime, date\n","result_path = os.path.join(save_result_dir, 'tf', 'unigru-attn', 'result-' + str(date.today()) + '-' + datetime.now().strftime(\"%H-%M-%S\") + '.csv')\n","print(result_path)\n","\n","starttime = time.time()\n","with open(result_path, mode='wt') as f:\n","  f.write('QID,Prediction\\n')\n","  for idx in range(test_df.shape[0]):\n","    doc = ' '.join([test_df['Question'].iloc[idx], test_df['Dialogue'].iloc[idx]])\n","    (result, inputs, attention_plot) = ss.evaluate(ss.encoder, ss.decoder, doc)\n","    result = test_df['QID'].iloc[idx] + ',' + result.replace(' ', '') + '\\n'\n","    f.write(result)\n","    if (idx + 1) % 20 == 0:\n","      print('processed: {}, at time: {:.2f}'.format(idx + 1, time.time() - starttime ))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/gdrive/My Drive/python-code/文本摘要-01/result/tf/unigru-attn/result-2019-12-24-03-02-55.csv\n","processed: 20, at time: 8.49\n","processed: 40, at time: 16.96\n","processed: 60, at time: 25.38\n","processed: 80, at time: 33.77\n","processed: 100, at time: 42.23\n","processed: 120, at time: 50.67\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-d4ef4abbc5b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Dialogue'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_plot\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'QID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m','\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-129c870b4605>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, encoder, decoder, doc)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworking_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_y_max_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;31m# storing the attention weights to plot later on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-129c870b4605>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, hidden, enc_output)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# x shape after passing through embedding == (batch_size, 1, embedding_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;31m# x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/layers/embeddings.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'int32'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'int64'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_lookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/embedding_ops.py\u001b[0m in \u001b[0;36membedding_lookup\u001b[0;34m(params, ids, partition_strategy, name, validate_indices, max_norm)\u001b[0m\n\u001b[1;32m    321\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m       \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m       transform_fn=None)\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/embedding_ops.py\u001b[0m in \u001b[0;36m_embedding_lookup_and_transform\u001b[0;34m(params, ids, partition_strategy, name, max_norm, transform_fn)\u001b[0m\n\u001b[1;32m    141\u001b[0m       \u001b[0;31m# params. Similar to the case np > 1 where parallel_dynamic_stitch is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m       \u001b[0;31m# outside the scioe of all with ops.colocate_with(params[p]).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m       \u001b[0;31m# Flatten the ids. There are two cases where we need to do this.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m   \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m   \u001b[0;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_handle_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m   3815\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m   3816\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Identity\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3817\u001b[0;31m         tld.op_callbacks, input)\n\u001b[0m\u001b[1;32m   3818\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3819\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"O25Y0YwHjhBz","colab_type":"code","outputId":"f924e443-8684-490f-9c6f-79883693e3ae","executionInfo":{"status":"ok","timestamp":1576899852726,"user_tz":-480,"elapsed":1595,"user":{"displayName":"Luo Yongliang","photoUrl":"","userId":"08228183385143629193"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["print(result)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["这种 情况 分析 下 。 <STOP> \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HMn83nrgpAiM","colab_type":"code","outputId":"e940081b-75fa-44c6-d00b-f1b99e96d178","executionInfo":{"status":"ok","timestamp":1576868607505,"user_tz":-480,"elapsed":1843,"user":{"displayName":"Luo Yongliang","photoUrl":"","userId":"08228183385143629193"}},"colab":{"base_uri":"https://localhost:8080/","height":215}},"source":["for i, (k, v) in enumerate(reverse_vocab.items()): \n","  if i > 10:\n","    break\n","  print(i, (k, v))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0 ('0', 0)\n","1 ('1', 1)\n","2 ('2', 2)\n","3 ('3', 3)\n","4 ('4', 4)\n","5 ('5', 5)\n","6 ('6', 6)\n","7 ('7', 7)\n","8 ('8', 8)\n","9 ('9', 9)\n","10 ('10', 10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_Et0VELivuoC","colab_type":"code","colab":{}},"source":["with open(reverse_vocab_path, \"r\", encoding='utf-8') as f:\n","  for line in f:\n","    print(line)\n","    pdb.set_trace()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DeAubm58wtBH","colab_type":"code","colab":{}},"source":["dict = {}\n","with open(vocab_path, \"r\", encoding='utf-8') as f:\n","    for line in f:\n","        kv = line.strip().split(\"\\t\")\n","        dict[kv[0]] = kv[1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-sM176GMwzb6","colab_type":"code","outputId":"cd1a8d1a-4dee-46e5-a59a-77442ecae75b","executionInfo":{"status":"ok","timestamp":1576869891923,"user_tz":-480,"elapsed":1176,"user":{"displayName":"Luo Yongliang","photoUrl":"","userId":"08228183385143629193"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["dict['汽车']"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'149'"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"rHebTi9qgsF4","colab_type":"code","colab":{}},"source":["ss.working_ds.X_max_len"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pSvrlWdag0d5","colab_type":"code","colab":{}},"source":["ss.document_as_tensor(doc)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O1Qgt3JSRNgu","colab_type":"code","colab":{}},"source":["ss.checkpoint_dir, ss.checkpoint_prefix"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PKM50EqAVtFD","colab_type":"code","colab":{}},"source":["ss.train_one_batch_for_restore(ss.encoder, ss.decoder, ss.dataset)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uKxfr-yPXfSG","colab_type":"code","colab":{}},"source":["ss.encoder.trainable_variables[-1], ss.decoder.trainable_variables[-1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wRoXrrygZdJY","colab_type":"code","colab":{}},"source":["ss.encoder.trainable_variables[-1], ss.decoder.trainable_variables[-1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wx_jFrIgh8m_","colab_type":"code","colab":{}},"source":["pdb.set_trace()\n","doc = sentence_proc(doc)\n","pdb.set_trace()\n","doc = pad_proc(doc, ss.working_ds.X_max_len, ss.working_ds.vocab)\n","pdb.set_trace()\n","doc = transform_data(doc, ss.working_ds.vocab)\n","pdb.set_trace()\n","doc = tf.convert_to_tensor([doc])\n","pdb.set_trace()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VTNBvSArsSSJ","colab_type":"code","outputId":"b0de310e-c140-4167-b2b7-be7668db95f4","executionInfo":{"status":"ok","timestamp":1577152664332,"user_tz":-480,"elapsed":1218,"user":{"displayName":"Luo Yongliang","photoUrl":"","userId":"08228183385143629193"}},"colab":{"base_uri":"https://localhost:8080/","height":292}},"source":["ss.working_ds.wv_model.most_similar(positive=['保险杠'])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n","  \"\"\"Entry point for launching an IPython kernel.\n","2019-12-24 01:57:46,364 : INFO : precomputing L2-norms of word weight vectors\n","/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["[('保险杆', 0.6531932353973389),\n"," ('叶子', 0.6307256817817688),\n"," ('后杠', 0.62998366355896),\n"," ('前保', 0.6294050216674805),\n"," ('前杠', 0.6288645267486572),\n"," ('中网', 0.6240440607070923),\n"," ('杠坏', 0.6200419664382935),\n"," ('龙门架', 0.6071912050247192),\n"," ('前护杠', 0.6040492057800293),\n"," ('翼子板', 0.5916516780853271)]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"SquwCUrKGmmT","colab_type":"code","outputId":"84adb335-b132-4f2a-ab48-5895dcbef027","executionInfo":{"status":"ok","timestamp":1576942706811,"user_tz":-480,"elapsed":4479,"user":{"displayName":"Luo Yongliang","photoUrl":"","userId":"08228183385143629193"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["dec_input = tf.expand_dims([ss.working_ds.vocab['<START>']]*16, 1)\n","print(dec_input.shape)\n","print()\n","dec_input = tf.expand_dims([ss.working_ds.vocab['<START>']]*16, 0)\n","print(dec_input.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(16, 1)\n","\n","(1, 16)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VofDBqj9ls2Y","colab_type":"code","colab":{}},"source":["working_ds = AutoCarDataSet()\n","working_ds.prepare_data(force_build=False)\n","working_ds.get_wv_model(force_build=False)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sHdN0UYoQMmS","colab_type":"text"},"source":["# [baidu](http://www.baidu.com)\n","\n"]},{"cell_type":"code","metadata":{"id":"4esqlYK_iwKX","colab_type":"code","colab":{}},"source":["encoder, decoder = create_codec()\n","\n","dataset = get_dataset()\n","loss_history = train_all(encoder, decoder, dataset, 1, True)\n","encoder.summary()\n","decoder.summary()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rYeJ5aTTUxmN","colab_type":"code","colab":{}},"source":["# !ls '/gdrive/My Drive/python-code/罗杰20191222-2'\n","!cp -avr '/gdrive/My Drive/python-code/罗杰20191222' '/gdrive/My Drive/python-code/罗杰20191222-2/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y7OfsVX-mQOw","colab_type":"code","colab":{}},"source":["encoder, decoder = create_codec()\n","train_for_restore(encoder, decoder, get_dataset())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7jW9s_c4auyZ","colab_type":"code","colab":{}},"source":["encoder.trainable_variables"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jWA6Uo2D2usE","colab_type":"code","outputId":"6cdf0fd2-6d47-4b83-ff72-b6ebd59b3313","executionInfo":{"status":"ok","timestamp":1577120006701,"user_tz":-480,"elapsed":2976,"user":{"displayName":"Luo Yongliang","photoUrl":"","userId":"08228183385143629193"}},"colab":{"base_uri":"https://localhost:8080/","height":251}},"source":["sys.path"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/tensorflow-2.1.0/python3.6',\n"," '',\n"," '/env/python',\n"," '/usr/lib/python36.zip',\n"," '/usr/lib/python3.6',\n"," '/usr/lib/python3.6/lib-dynload',\n"," '/usr/local/lib/python3.6/dist-packages',\n"," '/usr/lib/python3/dist-packages',\n"," '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n"," '/root/.ipython',\n"," '/gdrive/My Drive/python-code/文本摘要-01',\n"," '/gdrive/My Drive/python-code/文本摘要-01',\n"," '/gdrive/My Drive/python-code/文本摘要-01']"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"Ck5kyNS5nGUs","colab_type":"code","outputId":"043181b9-da2f-48a9-eb0e-413b7ffeaaf9","executionInfo":{"status":"ok","timestamp":1577120274148,"user_tz":-480,"elapsed":2568,"user":{"displayName":"Luo Yongliang","photoUrl":"","userId":"08228183385143629193"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["print(ss.checkpoint_prefix)\n","print(ss.checkpoint_dir)\n","from utils.inspect_checkpoint import call_main\n","\n","class ParamFlags():\n","  def __init__(self, file_name):\n","    self.file_name = file_name\n","    self.tensor_name = \"\"\n","    self.all_tensors = True\n","    self.all_tensor_names = True\n","    self.count_exclude_pattern = \"\"\n","\n","latest_file_name = os.path.join(ss.checkpoint_dir, 'ckpt-1')\n","FLAGS = ParamFlags(latest_file_name)\n","call_main(FLAGS, 'unused')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/gdrive/My Drive/python-code/文本摘要-01/checkpoints/tf/unigru_attn/ckpt\n","/gdrive/My Drive/python-code/文本摘要-01/checkpoints/tf/unigru_attn\n","tensor: _CHECKPOINTABLE_OBJECT_GRAPH (string) []\n","b'\\n\\x1f\\n\\x0b\\x08\\x01\\x12\\x07seq2seq\\n\\x10\\x08\\x02\\x12\\x0csave_counter\\nD\\n\\r\\x08\\x03\\x12\\toptimizer\\n\\x0b\\x08\\x04\\x12\\x07encoder\\n\\x0b\\x08\\x05\\x12\\x07decoder\\n\\x0c\\x12\\ncheckpoint\\n\\x0b\\x08\\x06\\x12\\x07dataset\\nI\\x12G\\n\\x0eVARIABLE_VALUE\\x12\\x0csave_counter\\x1a\\'save_counter/.ATTRIBUTES/VARIABLE_VALUE\\n\\xbc\\x02\\n\\x08\\x08\\x07\\x12\\x04iter\\n\\n\\x08\\x08\\x12\\x06beta_1\\n\\n\\x08\\t\\x12\\x06beta_2\\n\\t\\x08\\n\\x12\\x05decay\\n\\x11\\x08\\x0b\\x12\\rlearning_rate\\x1a\\x07\\x08\\x19\\x12\\x01m\\x18*\\x1a\\x07\\x08\\x1a\\x12\\x01m\\x18+\\x1a\\x07\\x08\\x1e\\x12\\x01m\\x18,\\x1a\\x07\\x08\\x1f\\x12\\x01m\\x18-\\x1a\\x07\\x08 \\x12\\x01m\\x18.\\x1a\\x07\\x08!\\x12\\x01m\\x18/\\x1a\\x07\\x08\"\\x12\\x01m\\x180\\x1a\\x07\\x08#\\x12\\x01m\\x181\\x1a\\x07\\x08$\\x12\\x01m\\x182\\x1a\\x07\\x08%\\x12\\x01m\\x183\\x1a\\x07\\x08&\\x12\\x01m\\x184\\x1a\\x07\\x08\\'\\x12\\x01m\\x185\\x1a\\x07\\x08(\\x12\\x01m\\x186\\x1a\\x07\\x08)\\x12\\x01m\\x187\\x1a\\x07\\x08\\x19\\x12\\x01v\\x188\\x1a\\x07\\x08\\x1a\\x12\\x01v\\x189\\x1a\\x07\\x08\\x1e\\x12\\x01v\\x18:\\x1a\\x07\\x08\\x1f\\x12\\x01v\\x18;\\x1a\\x07\\x08 \\x12\\x01v\\x18<\\x1a\\x07\\x08!\\x12\\x01v\\x18=\\x1a\\x07\\x08\"\\x12\\x01v\\x18>\\x1a\\x07\\x08#\\x12\\x01v\\x18?\\x1a\\x07\\x08$\\x12\\x01v\\x18@\\x1a\\x07\\x08%\\x12\\x01v\\x18A\\x1a\\x07\\x08&\\x12\\x01v\\x18B\\x1a\\x07\\x08\\'\\x12\\x01v\\x18C\\x1a\\x07\\x08(\\x12\\x01v\\x18D\\x1a\\x07\\x08)\\x12\\x01v\\x18E\\n\\x18\\n\\r\\x08\\x0c\\x12\\tembedding\\n\\x07\\x08\\r\\x12\\x03gru\\n/\\n\\r\\x08\\x0e\\x12\\tembedding\\n\\x07\\x08\\x0f\\x12\\x03gru\\n\\x06\\x08\\x10\\x12\\x02fc\\n\\r\\x08\\x11\\x12\\tattention\\n\\x16\\n\\x14\\x08\\x12\\x12\\x10_variant_tracker\\nP\\x12N\\n\\x0eVARIABLE_VALUE\\x12\\tAdam/iter\\x1a1seq2seq/optimizer/iter/.ATTRIBUTES/VARIABLE_VALUE\\nT\\x12R\\n\\x0eVARIABLE_VALUE\\x12\\x0bAdam/beta_1\\x1a3seq2seq/optimizer/beta_1/.ATTRIBUTES/VARIABLE_VALUE\\nT\\x12R\\n\\x0eVARIABLE_VALUE\\x12\\x0bAdam/beta_2\\x1a3seq2seq/optimizer/beta_2/.ATTRIBUTES/VARIABLE_VALUE\\nR\\x12P\\n\\x0eVARIABLE_VALUE\\x12\\nAdam/decay\\x1a2seq2seq/optimizer/decay/.ATTRIBUTES/VARIABLE_VALUE\\nb\\x12`\\n\\x0eVARIABLE_VALUE\\x12\\x12Adam/learning_rate\\x1a:seq2seq/optimizer/learning_rate/.ATTRIBUTES/VARIABLE_VALUE\\n\\x10\\n\\x0e\\x08\\x13\\x12\\nembeddings\\n\\x1a\\n\\x08\\x08\\x14\\x12\\x04cell\\n\\x0e\\x08\\x15\\x12\\nstate_spec\\n\\x10\\n\\x0e\\x08\\x16\\x12\\nembeddings\\n\\x1a\\n\\x08\\x08\\x17\\x12\\x04cell\\n\\x0e\\x08\\x18\\x12\\nstate_spec\\n\\x16\\n\\n\\x08\\x19\\x12\\x06kernel\\n\\x08\\x08\\x1a\\x12\\x04bias\\n\\x17\\n\\x06\\x08\\x1b\\x12\\x02W1\\n\\x06\\x08\\x1c\\x12\\x02W2\\n\\x05\\x08\\x1d\\x12\\x01V\\n\\x00\\n|\\x12z\\n\\x0eVARIABLE_VALUE\\x12\\'unidir_gru_encoder/embedding/embeddings\\x1a?seq2seq/encoder/embedding/embeddings/.ATTRIBUTES/VARIABLE_VALUE\\n,\\n\\n\\x08\\x1e\\x12\\x06kernel\\n\\x14\\x08\\x1f\\x12\\x10recurrent_kernel\\n\\x08\\x08 \\x12\\x04bias\\n\\x00\\n\\x8b\\x01\\x12\\x88\\x01\\n\\x0eVARIABLE_VALUE\\x125uni_gru_decoder_with_attention/embedding_1/embeddings\\x1a?seq2seq/decoder/embedding/embeddings/.ATTRIBUTES/VARIABLE_VALUE\\n,\\n\\n\\x08!\\x12\\x06kernel\\n\\x14\\x08\"\\x12\\x10recurrent_kernel\\n\\x08\\x08#\\x12\\x04bias\\n\\x00\\nu\\x12s\\n\\x0eVARIABLE_VALUE\\x12+uni_gru_decoder_with_attention/dense/kernel\\x1a4seq2seq/decoder/fc/kernel/.ATTRIBUTES/VARIABLE_VALUE\\nq\\x12o\\n\\x0eVARIABLE_VALUE\\x12)uni_gru_decoder_with_attention/dense/bias\\x1a2seq2seq/decoder/fc/bias/.ATTRIBUTES/VARIABLE_VALUE\\n\\x16\\n\\n\\x08$\\x12\\x06kernel\\n\\x08\\x08%\\x12\\x04bias\\n\\x16\\n\\n\\x08&\\x12\\x06kernel\\n\\x08\\x08\\'\\x12\\x04bias\\n\\x16\\n\\n\\x08(\\x12\\x06kernel\\n\\x08\\x08)\\x12\\x04bias\\nm\\x12k\\n\\x0eVARIABLE_VALUE\\x12\\x1dunidir_gru_encoder/gru/kernel\\x1a:seq2seq/encoder/gru/cell/kernel/.ATTRIBUTES/VARIABLE_VALUE\\n\\x81\\x01\\x12\\x7f\\n\\x0eVARIABLE_VALUE\\x12\\'unidir_gru_encoder/gru/recurrent_kernel\\x1aDseq2seq/encoder/gru/cell/recurrent_kernel/.ATTRIBUTES/VARIABLE_VALUE\\ni\\x12g\\n\\x0eVARIABLE_VALUE\\x12\\x1bunidir_gru_encoder/gru/bias\\x1a8seq2seq/encoder/gru/cell/bias/.ATTRIBUTES/VARIABLE_VALUE\\n{\\x12y\\n\\x0eVARIABLE_VALUE\\x12+uni_gru_decoder_with_attention/gru_1/kernel\\x1a:seq2seq/decoder/gru/cell/kernel/.ATTRIBUTES/VARIABLE_VALUE\\n\\x90\\x01\\x12\\x8d\\x01\\n\\x0eVARIABLE_VALUE\\x125uni_gru_decoder_with_attention/gru_1/recurrent_kernel\\x1aDseq2seq/decoder/gru/cell/recurrent_kernel/.ATTRIBUTES/VARIABLE_VALUE\\nw\\x12u\\n\\x0eVARIABLE_VALUE\\x12)uni_gru_decoder_with_attention/gru_1/bias\\x1a8seq2seq/decoder/gru/cell/bias/.ATTRIBUTES/VARIABLE_VALUE\\n\\x95\\x01\\x12\\x92\\x01\\n\\x0eVARIABLE_VALUE\\x12@uni_gru_decoder_with_attention/bahdanau_attention/dense_1/kernel\\x1a>seq2seq/decoder/attention/W1/kernel/.ATTRIBUTES/VARIABLE_VALUE\\n\\x91\\x01\\x12\\x8e\\x01\\n\\x0eVARIABLE_VALUE\\x12>uni_gru_decoder_with_attention/bahdanau_attention/dense_1/bias\\x1a<seq2seq/decoder/attention/W1/bias/.ATTRIBUTES/VARIABLE_VALUE\\n\\x95\\x01\\x12\\x92\\x01\\n\\x0eVARIABLE_VALUE\\x12@uni_gru_decoder_with_attention/bahdanau_attention/dense_2/kernel\\x1a>seq2seq/decoder/attention/W2/kernel/.ATTRIBUTES/VARIABLE_VALUE\\n\\x91\\x01\\x12\\x8e\\x01\\n\\x0eVARIABLE_VALUE\\x12>uni_gru_decoder_with_attention/bahdanau_attention/dense_2/bias\\x1a<seq2seq/decoder/attention/W2/bias/.ATTRIBUTES/VARIABLE_VALUE\\n\\x94\\x01\\x12\\x91\\x01\\n\\x0eVARIABLE_VALUE\\x12@uni_gru_decoder_with_attention/bahdanau_attention/dense_3/kernel\\x1a=seq2seq/decoder/attention/V/kernel/.ATTRIBUTES/VARIABLE_VALUE\\n\\x90\\x01\\x12\\x8d\\x01\\n\\x0eVARIABLE_VALUE\\x12>uni_gru_decoder_with_attention/bahdanau_attention/dense_3/bias\\x1a;seq2seq/decoder/attention/V/bias/.ATTRIBUTES/VARIABLE_VALUE\\n\\xa1\\x01\\x12\\x9e\\x01\\n\\x0eVARIABLE_VALUE\\x122Adam/uni_gru_decoder_with_attention/dense/kernel/m\\x1aXseq2seq/decoder/fc/kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE\\n\\x9d\\x01\\x12\\x9a\\x01\\n\\x0eVARIABLE_VALUE\\x120Adam/uni_gru_decoder_with_attention/dense/bias/m\\x1aVseq2seq/decoder/fc/bias/.OPTIMIZER_SLOT/seq2seq/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE\\n\\x99\\x01\\x12\\x96\\x01\\n\\x0eVARIABLE_VALUE\\x12$Adam/unidir_gru_encoder/gru/kernel/m\\x1a^seq2seq/encoder/gru/cell/kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE\\n\\xad\\x01\\x12\\xaa\\x01\\n\\x0eVARIABLE_VALUE\\x12.Adam/unidir_gru_encoder/gru/recurrent_kernel/m\\x1ahseq2seq/encoder/gru/cell/recurrent_kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE\\n\\x95\\x01\\x12\\x92\\x01\\n\\x0eVARIABLE_VALUE\\x12\"Adam/unidir_gru_encoder/gru/bias/m\\x1a\\\\seq2seq/encoder/gru/cell/bias/.OPTIMIZER_SLOT/seq2seq/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE\\n\\xa7\\x01\\x12\\xa4\\x01\\n\\x0eVARIABLE_VALUE\\x122Adam/uni_gru_decoder_with_attention/gru_1/kernel/m\\x1a^seq2seq/decoder/gru/cell/kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE\\n\\xbb\\x01\\x12\\xb8\\x01\\n\\x0eVARIABLE_VALUE\\x12<Adam/uni_gru_decoder_with_attention/gru_1/recurrent_kernel/m\\x1ahseq2seq/decoder/gru/cell/recurrent_kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE\\n\\xa3\\x01\\x12\\xa0\\x01\\n\\x0eVARIABLE_VALUE\\x120Adam/uni_gru_decoder_with_attention/gru_1/bias/m\\x1a\\\\seq2seq/decoder/gru/cell/bias/.OPTIMIZER_SLOT/seq2seq/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE\\n\\xc0\\x01\\x12\\xbd\\x01\\n\\x0eVARIABLE_VALUE\\x12GAdam/uni_gru_decoder_with_attention/bahdanau_attention/dense_1/kernel/m\\x1abseq2seq/decoder/attention/W1/kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE\\n\\xbc\\x01\\x12\\xb9\\x01\\n\\x0eVARIABLE_VALUE\\x12EAdam/uni_gru_decoder_with_attention/bahdanau_attention/dense_1/bias/m\\x1a`seq2seq/decoder/attention/W1/bias/.OPTIMIZER_SLOT/seq2seq/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE\\n\\xc0\\x01\\x12\\xbd\\x01\\n\\x0eVARIABLE_VALUE\\x12GAdam/uni_gru_decoder_with_attention/bahdanau_attention/dense_2/kernel/m\\x1abseq2seq/decoder/attention/W2/kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE\\n\\xbc\\x01\\x12\\xb9\\x01\\n\\x0eVARIABLE_VALUE\\x12EAdam/uni_gru_decoder_with_attention/bahdanau_attention/dense_2/bias/m\\x1a`seq2seq/decoder/attention/W2/bias/.OPTIMIZER_SLOT/seq2seq/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE\\n\\xbf\\x01\\x12\\xbc\\x01\\n\\x0eVARIABLE_VALUE\\x12GAdam/uni_gru_decoder_with_attention/bahdanau_attention/dense_3/kernel/m\\x1aaseq2seq/decoder/attention/V/kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE\\n\\xbb\\x01\\x12\\xb8\\x01\\n\\x0eVARIABLE_VALUE\\x12EAdam/uni_gru_decoder_with_attention/bahdanau_attention/dense_3/bias/m\\x1a_seq2seq/decoder/attention/V/bias/.OPTIMIZER_SLOT/seq2seq/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE\\n\\xa1\\x01\\x12\\x9e\\x01\\n\\x0eVARIABLE_VALUE\\x122Adam/uni_gru_decoder_with_attention/dense/kernel/v\\x1aXseq2seq/decoder/fc/kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE\\n\\x9d\\x01\\x12\\x9a\\x01\\n\\x0eVARIABLE_VALUE\\x120Adam/uni_gru_decoder_with_attention/dense/bias/v\\x1aVseq2seq/decoder/fc/bias/.OPTIMIZER_SLOT/seq2seq/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE\\n\\x99\\x01\\x12\\x96\\x01\\n\\x0eVARIABLE_VALUE\\x12$Adam/unidir_gru_encoder/gru/kernel/v\\x1a^seq2seq/encoder/gru/cell/kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE\\n\\xad\\x01\\x12\\xaa\\x01\\n\\x0eVARIABLE_VALUE\\x12.Adam/unidir_gru_encoder/gru/recurrent_kernel/v\\x1ahseq2seq/encoder/gru/cell/recurrent_kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE\\n\\x95\\x01\\x12\\x92\\x01\\n\\x0eVARIABLE_VALUE\\x12\"Adam/unidir_gru_encoder/gru/bias/v\\x1a\\\\seq2seq/encoder/gru/cell/bias/.OPTIMIZER_SLOT/seq2seq/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE\\n\\xa7\\x01\\x12\\xa4\\x01\\n\\x0eVARIABLE_VALUE\\x122Adam/uni_gru_decoder_with_attention/gru_1/kernel/v\\x1a^seq2seq/decoder/gru/cell/kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE\\n\\xbb\\x01\\x12\\xb8\\x01\\n\\x0eVARIABLE_VALUE\\x12<Adam/uni_gru_decoder_with_attention/gru_1/recurrent_kernel/v\\x1ahseq2seq/decoder/gru/cell/recurrent_kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE\\n\\xa3\\x01\\x12\\xa0\\x01\\n\\x0eVARIABLE_VALUE\\x120Adam/uni_gru_decoder_with_attention/gru_1/bias/v\\x1a\\\\seq2seq/decoder/gru/cell/bias/.OPTIMIZER_SLOT/seq2seq/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE\\n\\xc0\\x01\\x12\\xbd\\x01\\n\\x0eVARIABLE_VALUE\\x12GAdam/uni_gru_decoder_with_attention/bahdanau_attention/dense_1/kernel/v\\x1abseq2seq/decoder/attention/W1/kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE\\n\\xbc\\x01\\x12\\xb9\\x01\\n\\x0eVARIABLE_VALUE\\x12EAdam/uni_gru_decoder_with_attention/bahdanau_attention/dense_1/bias/v\\x1a`seq2seq/decoder/attention/W1/bias/.OPTIMIZER_SLOT/seq2seq/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE\\n\\xc0\\x01\\x12\\xbd\\x01\\n\\x0eVARIABLE_VALUE\\x12GAdam/uni_gru_decoder_with_attention/bahdanau_attention/dense_2/kernel/v\\x1abseq2seq/decoder/attention/W2/kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE\\n\\xbc\\x01\\x12\\xb9\\x01\\n\\x0eVARIABLE_VALUE\\x12EAdam/uni_gru_decoder_with_attention/bahdanau_attention/dense_2/bias/v\\x1a`seq2seq/decoder/attention/W2/bias/.OPTIMIZER_SLOT/seq2seq/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE\\n\\xbf\\x01\\x12\\xbc\\x01\\n\\x0eVARIABLE_VALUE\\x12GAdam/uni_gru_decoder_with_attention/bahdanau_attention/dense_3/kernel/v\\x1aaseq2seq/decoder/attention/V/kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE\\n\\xbb\\x01\\x12\\xb8\\x01\\n\\x0eVARIABLE_VALUE\\x12EAdam/uni_gru_decoder_with_attention/bahdanau_attention/dense_3/bias/v\\x1a_seq2seq/decoder/attention/V/bias/.OPTIMIZER_SLOT/seq2seq/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE'\n","tensor: save_counter/.ATTRIBUTES/VARIABLE_VALUE (int64) []\n","1\n","tensor: seq2seq/decoder/attention/V/bias/.ATTRIBUTES/VARIABLE_VALUE (float32) [1]\n","[0.0001586]\n","tensor: seq2seq/decoder/attention/V/bias/.OPTIMIZER_SLOT/seq2seq/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE (float32) [1]\n","[-3.1261028e-08]\n","tensor: seq2seq/decoder/attention/V/bias/.OPTIMIZER_SLOT/seq2seq/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE (float32) [1]\n","[8.089426e-17]\n","tensor: seq2seq/decoder/attention/V/kernel/.ATTRIBUTES/VARIABLE_VALUE (float32) [256, 1]\n","[[ 0.05133817]\n"," [ 0.11596318]\n"," [-0.0302079 ]\n"," [-0.12844503]\n"," [ 0.02185008]\n"," [-0.04363874]\n"," [-0.13942885]\n"," [-0.08075178]\n"," [ 0.13706681]\n"," [ 0.05392231]\n"," [-0.06026432]\n"," [ 0.12622115]\n"," [ 0.10134812]\n"," [-0.08485925]\n"," [-0.0170658 ]\n"," [ 0.1329197 ]\n"," [-0.1531739 ]\n"," [-0.12367546]\n"," [-0.04660399]\n"," [ 0.13844281]\n"," [-0.07684053]\n"," [ 0.15518783]\n"," [ 0.09605631]\n"," [-0.04652027]\n"," [ 0.00391847]\n"," [-0.09937893]\n"," [-0.13665675]\n"," [ 0.15017243]\n"," [-0.13453029]\n"," [-0.11780532]\n"," [ 0.06102747]\n"," [ 0.08304819]\n"," [ 0.10934069]\n"," [-0.12266275]\n"," [-0.01939949]\n"," [-0.0990522 ]\n"," [-0.03914167]\n"," [ 0.09967055]\n"," [-0.02369004]\n"," [ 0.11723824]\n"," [ 0.11860065]\n"," [-0.04041566]\n"," [-0.07915336]\n"," [-0.05151727]\n"," [-0.1452019 ]\n"," [-0.03702069]\n"," [-0.03849159]\n"," [-0.00837571]\n"," [ 0.15099739]\n"," [ 0.13860506]\n"," [-0.1198054 ]\n"," [-0.09529692]\n"," [-0.09074474]\n"," [-0.09192157]\n"," [ 0.09318412]\n"," [ 0.09320821]\n"," [ 0.03453272]\n"," [-0.12260745]\n"," [-0.0386819 ]\n"," [ 0.11049701]\n"," [-0.097285  ]\n"," [-0.06898221]\n"," [-0.1448628 ]\n"," [ 0.00712985]\n"," [-0.02563656]\n"," [-0.10165907]\n"," [ 0.05765577]\n"," [-0.01429139]\n"," [ 0.12780821]\n"," [ 0.09425303]\n"," [ 0.03851008]\n"," [-0.04611582]\n"," [-0.13669595]\n"," [ 0.04023303]\n"," [-0.12017967]\n"," [ 0.13506672]\n"," [ 0.11249678]\n"," [-0.13102049]\n"," [ 0.07712824]\n"," [-0.14395653]\n"," [-0.1058048 ]\n"," [-0.0643061 ]\n"," [ 0.10087112]\n"," [-0.0665139 ]\n"," [ 0.09574004]\n"," [-0.11969186]\n"," [-0.0477513 ]\n"," [-0.14057611]\n"," [ 0.07175916]\n"," [ 0.00777624]\n"," [-0.01042126]\n"," [-0.09569119]\n"," [-0.03591284]\n"," [-0.03023217]\n"," [ 0.03844052]\n"," [-0.10656602]\n"," [-0.14753348]\n"," [ 0.09599348]\n"," [-0.01534025]\n"," [-0.05069922]\n"," [ 0.05328629]\n"," [-0.02679699]\n"," [-0.1545373 ]\n"," [ 0.13672756]\n"," [-0.15605429]\n"," [-0.0844494 ]\n"," [-0.04976935]\n"," [ 0.1405939 ]\n"," [-0.09396074]\n"," [ 0.13185963]\n"," [ 0.07336665]\n"," [ 0.13173245]\n"," [ 0.10330374]\n"," [ 0.1436971 ]\n"," [ 0.00160367]\n"," [ 0.01353686]\n"," [ 0.00181122]\n"," [-0.02097512]\n"," [ 0.03694106]\n"," [ 0.05008018]\n"," [ 0.11924076]\n"," [-0.04048955]\n"," [-0.00674271]\n"," [-0.12959895]\n"," [-0.12349882]\n"," [-0.10604385]\n"," [ 0.02483835]\n"," [-0.04552767]\n"," [ 0.09306786]\n"," [ 0.06161043]\n"," [-0.09207574]\n"," [ 0.03470076]\n"," [ 0.01387127]\n"," [-0.05195316]\n"," [-0.1489715 ]\n"," [-0.02602064]\n"," [ 0.06150465]\n"," [ 0.08305854]\n"," [-0.1126494 ]\n"," [ 0.14165343]\n"," [-0.07865097]\n"," [ 0.03888764]\n"," [-0.09737115]\n"," [ 0.10316887]\n"," [ 0.10142792]\n"," [-0.14694646]\n"," [-0.13648626]\n"," [ 0.11750781]\n"," [-0.04389869]\n"," [-0.11136809]\n"," [-0.11673789]\n"," [-0.04657935]\n"," [-0.05940859]\n"," [-0.02906556]\n"," [-0.06249937]\n"," [-0.03046806]\n"," [ 0.08653578]\n"," [-0.08341646]\n"," [ 0.05877471]\n"," [ 0.11022239]\n"," [-0.04801637]\n"," [-0.05678782]\n"," [ 0.06603882]\n"," [-0.02314141]\n"," [-0.0750434 ]\n"," [-0.0946234 ]\n"," [ 0.12584002]\n"," [-0.08796918]\n"," [ 0.08437243]\n"," [-0.04750384]\n"," [ 0.10082182]\n"," [-0.11771913]\n"," [-0.03734742]\n"," [ 0.02932798]\n"," [-0.01745148]\n"," [ 0.13237308]\n"," [-0.13361645]\n"," [-0.07494419]\n"," [-0.09458897]\n"," [ 0.13379017]\n"," [ 0.12921028]\n"," [-0.09125893]\n"," [ 0.14255655]\n"," [-0.02894536]\n"," [ 0.01567744]\n"," [-0.07467468]\n"," [-0.08106097]\n"," [-0.06989262]\n"," [ 0.11522982]\n"," [-0.07356156]\n"," [-0.11636797]\n"," [-0.07262976]\n"," [ 0.13704233]\n"," [ 0.13695149]\n"," [-0.13712975]\n"," [ 0.1312827 ]\n"," [ 0.01782352]\n"," [-0.03402454]\n"," [-0.06268016]\n"," [-0.01558741]\n"," [-0.07381938]\n"," [ 0.06431267]\n"," [ 0.14111528]\n"," [-0.12928344]\n"," [-0.12892658]\n"," [ 0.07787058]\n"," [ 0.1320201 ]\n"," [-0.0082793 ]\n"," [-0.07390618]\n"," [ 0.07797016]\n"," [-0.13084073]\n"," [-0.14409842]\n"," [ 0.12188162]\n"," [ 0.07048161]\n"," [ 0.08523983]\n"," [-0.0973797 ]\n"," [ 0.08871524]\n"," [-0.15141915]\n"," [ 0.11429444]\n"," [ 0.10360787]\n"," [-0.07772665]\n"," [ 0.14842093]\n"," [ 0.13696967]\n"," [ 0.15290144]\n"," [-0.08758119]\n"," [-0.12068085]\n"," [ 0.03694225]\n"," [-0.13055165]\n"," [ 0.1293685 ]\n"," [ 0.09447423]\n"," [ 0.13835645]\n"," [-0.02843214]\n"," [-0.14939426]\n"," [ 0.08023565]\n"," [ 0.140976  ]\n"," [ 0.06427606]\n"," [ 0.13169286]\n"," [ 0.14546627]\n"," [-0.07246446]\n"," [ 0.06826036]\n"," [ 0.09936342]\n"," [ 0.07997371]\n"," [-0.09047178]\n"," [ 0.14358898]\n"," [-0.11342278]\n"," [ 0.01378051]\n"," [-0.09290369]\n"," [ 0.00347445]\n"," [-0.08228226]\n"," [ 0.05456738]\n"," [ 0.06935154]\n"," [ 0.03668466]\n"," [-0.01654509]\n"," [ 0.04666692]\n"," [-0.08877914]\n"," [ 0.00223016]]\n","tensor: seq2seq/decoder/attention/V/kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE (float32) [256, 1]\n","[[-0.05755831]\n"," [ 0.05031582]\n"," [-0.01419846]\n"," [-0.02160309]\n"," [ 0.06124246]\n"," [ 0.01297398]\n"," [ 0.00898893]\n"," [-0.04681675]\n"," [ 0.01121882]\n"," [ 0.0059427 ]\n"," [-0.04238432]\n"," [ 0.01097406]\n"," [ 0.00434946]\n"," [ 0.01389844]\n"," [ 0.00644267]\n"," [ 0.01451038]\n"," [ 0.04900436]\n"," [ 0.04036551]\n"," [-0.04730406]\n"," [ 0.00095652]\n"," [ 0.00431272]\n"," [-0.0553325 ]\n"," [ 0.01929961]\n"," [-0.01093666]\n"," [-0.02480146]\n"," [-0.01581575]\n"," [-0.0137719 ]\n"," [-0.01981671]\n"," [-0.01307434]\n"," [ 0.06656098]\n"," [ 0.03617727]\n"," [-0.01135944]\n"," [-0.03971744]\n"," [-0.04283117]\n"," [ 0.01125117]\n"," [ 0.0362236 ]\n"," [-0.0478522 ]\n"," [-0.00161476]\n"," [ 0.02249602]\n"," [ 0.02110725]\n"," [ 0.00158329]\n"," [ 0.00636854]\n"," [ 0.00978972]\n"," [ 0.00641091]\n"," [-0.08579673]\n"," [-0.0221471 ]\n"," [-0.00514113]\n"," [-0.0063511 ]\n"," [-0.01882449]\n"," [ 0.04144104]\n"," [ 0.04578555]\n"," [ 0.05042242]\n"," [ 0.02663013]\n"," [ 0.01782153]\n"," [-0.05609624]\n"," [-0.00977095]\n"," [-0.00222656]\n"," [ 0.03144911]\n"," [ 0.02641781]\n"," [-0.04228159]\n"," [ 0.01752409]\n"," [ 0.02206244]\n"," [-0.02256904]\n"," [ 0.00858504]\n"," [ 0.03422941]\n"," [ 0.04269138]\n"," [-0.06369834]\n"," [-0.04343068]\n"," [-0.03234501]\n"," [-0.00541772]\n"," [ 0.00880167]\n"," [ 0.0560992 ]\n"," [ 0.03881012]\n"," [-0.000838  ]\n"," [-0.00450382]\n"," [-0.04516331]\n"," [-0.02711983]\n"," [-0.02463692]\n"," [-0.03045896]\n"," [ 0.00299381]\n"," [ 0.02080075]\n"," [-0.01717292]\n"," [ 0.03161122]\n"," [-0.01408296]\n"," [-0.04925041]\n"," [ 0.04033653]\n"," [ 0.00479027]\n"," [ 0.0565745 ]\n"," [-0.02662036]\n"," [-0.01885063]\n"," [ 0.04940702]\n"," [ 0.00558097]\n"," [-0.01276823]\n"," [ 0.04628761]\n"," [-0.02993857]\n"," [-0.02056942]\n"," [ 0.0355785 ]\n"," [-0.04138019]\n"," [ 0.01384173]\n"," [-0.01213985]\n"," [-0.03425174]\n"," [-0.00302771]\n"," [ 0.02027127]\n"," [ 0.00957644]\n"," [ 0.06698302]\n"," [-0.06812448]\n"," [-0.0420744 ]\n"," [-0.05449719]\n"," [-0.01314898]\n"," [-0.04016164]\n"," [-0.02050989]\n"," [-0.0105123 ]\n"," [-0.03058422]\n"," [-0.04222457]\n"," [-0.00313777]\n"," [ 0.04389237]\n"," [-0.01983004]\n"," [ 0.0688911 ]\n"," [-0.06780306]\n"," [-0.02145987]\n"," [ 0.05970896]\n"," [ 0.05679145]\n"," [ 0.0159748 ]\n"," [-0.00431447]\n"," [ 0.01568875]\n"," [-0.01166397]\n"," [-0.01202684]\n"," [-0.05770463]\n"," [-0.0349647 ]\n"," [-0.04063446]\n"," [-0.0539652 ]\n"," [-0.05125963]\n"," [ 0.00809665]\n"," [-0.0303484 ]\n"," [ 0.04347005]\n"," [-0.01473646]\n"," [-0.02511224]\n"," [-0.00690615]\n"," [ 0.04869471]\n"," [ 0.02669592]\n"," [-0.01096198]\n"," [ 0.06492603]\n"," [ 0.02876676]\n"," [ 0.02534876]\n"," [ 0.02066331]\n"," [ 0.00504435]\n"," [-0.01455343]\n"," [-0.0342095 ]\n"," [ 0.00393811]\n"," [-0.01122443]\n"," [ 0.03836761]\n"," [-0.05044117]\n"," [ 0.00186628]\n"," [-0.03088584]\n"," [-0.07180794]\n"," [-0.09817254]\n"," [-0.01284975]\n"," [-0.05618646]\n"," [ 0.07883006]\n"," [ 0.04045378]\n"," [ 0.02267916]\n"," [ 0.05337168]\n"," [-0.01467183]\n"," [ 0.055543  ]\n"," [-0.0117415 ]\n"," [ 0.00077813]\n"," [-0.06395475]\n"," [-0.02068341]\n"," [-0.05072697]\n"," [ 0.00270129]\n"," [-0.03822362]\n"," [-0.00227393]\n"," [-0.0163669 ]\n"," [-0.04079278]\n"," [-0.03876847]\n"," [ 0.0336954 ]\n"," [ 0.04958274]\n"," [ 0.00354855]\n"," [ 0.01662325]\n"," [ 0.05712079]\n"," [ 0.00333671]\n"," [-0.01512577]\n"," [-0.02498992]\n"," [-0.03250553]\n"," [ 0.03584865]\n"," [ 0.01159226]\n"," [ 0.02260249]\n"," [-0.02439481]\n"," [ 0.02602742]\n"," [ 0.00882262]\n"," [ 0.00017056]\n"," [ 0.03784761]\n"," [-0.06799147]\n"," [-0.02383353]\n"," [-0.05538078]\n"," [-0.09585324]\n"," [ 0.05400601]\n"," [-0.0266335 ]\n"," [-0.01493089]\n"," [-0.07363162]\n"," [-0.00907239]\n"," [-0.01139853]\n"," [ 0.01999138]\n"," [-0.04225118]\n"," [ 0.07505053]\n"," [-0.0087322 ]\n"," [-0.06635972]\n"," [ 0.01230897]\n"," [-0.01927257]\n"," [-0.04336166]\n"," [ 0.0257226 ]\n"," [ 0.02506648]\n"," [-0.0319532 ]\n"," [-0.05827516]\n"," [ 0.02957116]\n"," [-0.02043016]\n"," [ 0.0234824 ]\n"," [ 0.014403  ]\n"," [-0.0382759 ]\n"," [-0.06889673]\n"," [ 0.01069594]\n"," [-0.00269889]\n"," [-0.05891088]\n"," [-0.03296455]\n"," [-0.01275616]\n"," [-0.01443724]\n"," [ 0.00047228]\n"," [-0.05833855]\n"," [-0.03168241]\n"," [ 0.03753414]\n"," [-0.01913461]\n"," [-0.01679889]\n"," [-0.05037921]\n"," [ 0.00184494]\n"," [-0.02363585]\n"," [ 0.02749161]\n"," [ 0.01556244]\n"," [ 0.00877554]\n"," [ 0.0330974 ]\n"," [-0.00396263]\n"," [-0.01344628]\n"," [-0.02943498]\n"," [ 0.00093375]\n"," [ 0.04177963]\n"," [ 0.00281426]\n"," [ 0.01377638]\n"," [ 0.06204217]\n"," [ 0.00633717]\n"," [ 0.03713627]\n"," [ 0.00538987]\n"," [ 0.00562071]\n"," [ 0.01211155]\n"," [ 0.01881999]\n"," [-0.02877998]\n"," [-0.05597139]\n"," [ 0.04232555]]\n","tensor: seq2seq/decoder/attention/V/kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE (float32) [256, 1]\n","[[1.71163600e-04]\n"," [1.36692790e-04]\n"," [1.44866099e-05]\n"," [3.35116201e-05]\n"," [2.02367446e-04]\n"," [1.07019641e-05]\n"," [3.61044954e-06]\n"," [1.21429111e-04]\n"," [1.66425107e-05]\n"," [3.18012962e-06]\n"," [9.93434733e-05]\n"," [7.18228785e-06]\n"," [1.49439293e-05]\n"," [2.56444891e-05]\n"," [2.27424584e-06]\n"," [1.47420869e-05]\n"," [1.34198635e-04]\n"," [8.58582061e-05]\n"," [1.21507685e-04]\n"," [5.54078269e-07]\n"," [1.20456625e-05]\n"," [1.60628304e-04]\n"," [2.34588115e-05]\n"," [7.31280124e-06]\n"," [3.24990579e-05]\n"," [1.23964965e-05]\n"," [1.13034430e-05]\n"," [3.34673095e-05]\n"," [1.36095550e-05]\n"," [2.39255882e-04]\n"," [7.67206511e-05]\n"," [1.47406281e-05]\n"," [8.89576258e-05]\n"," [9.95131995e-05]\n"," [1.08198519e-05]\n"," [8.00660710e-05]\n"," [1.24069717e-04]\n"," [1.51232098e-05]\n"," [2.71084045e-05]\n"," [2.73131409e-05]\n"," [1.40407985e-06]\n"," [4.29786814e-06]\n"," [6.62665479e-06]\n"," [2.93211588e-06]\n"," [4.01207333e-04]\n"," [3.23273271e-05]\n"," [2.73540854e-06]\n"," [2.92471486e-06]\n"," [3.64917396e-05]\n"," [9.15251949e-05]\n"," [1.14790375e-04]\n"," [1.46521517e-04]\n"," [3.52656316e-05]\n"," [2.65505569e-05]\n"," [1.81448369e-04]\n"," [1.39522226e-05]\n"," [5.46983756e-06]\n"," [5.12372208e-05]\n"," [3.44496038e-05]\n"," [9.62068734e-05]\n"," [1.53225046e-05]\n"," [2.66948737e-05]\n"," [2.94391284e-05]\n"," [4.86034378e-06]\n"," [6.74218682e-05]\n"," [1.00405727e-04]\n"," [2.18790708e-04]\n"," [1.15142095e-04]\n"," [6.07067013e-05]\n"," [5.61703382e-06]\n"," [9.07092908e-06]\n"," [1.64270998e-04]\n"," [8.53483652e-05]\n"," [5.70589634e-07]\n"," [6.08278651e-06]\n"," [1.11408495e-04]\n"," [4.19434618e-05]\n"," [3.67476641e-05]\n"," [5.63347057e-05]\n"," [2.60695851e-05]\n"," [2.13358453e-05]\n"," [1.86238740e-05]\n"," [5.37729538e-05]\n"," [1.55737489e-05]\n"," [1.31511217e-04]\n"," [8.75900150e-05]\n"," [1.21811820e-06]\n"," [1.63633216e-04]\n"," [4.13799644e-05]\n"," [2.85488877e-05]\n"," [1.30451270e-04]\n"," [1.28672436e-05]\n"," [8.81748292e-06]\n"," [1.15942923e-04]\n"," [4.57519054e-05]\n"," [2.39328110e-05]\n"," [6.85876003e-05]\n"," [1.00554469e-04]\n"," [1.05725239e-05]\n"," [1.06495345e-05]\n"," [6.20722130e-05]\n"," [8.71421707e-06]\n"," [2.13127150e-05]\n"," [5.71546161e-06]\n"," [2.58427783e-04]\n"," [2.53913895e-04]\n"," [9.51224793e-05]\n"," [1.82249918e-04]\n"," [9.97406278e-06]\n"," [8.70123040e-05]\n"," [2.24654104e-05]\n"," [2.09796654e-05]\n"," [5.79665902e-05]\n"," [9.61335536e-05]\n"," [5.62852256e-06]\n"," [1.09028704e-04]\n"," [3.31396841e-05]\n"," [2.61618348e-04]\n"," [2.44604045e-04]\n"," [2.45332958e-05]\n"," [1.92770764e-04]\n"," [1.68632134e-04]\n"," [1.34706388e-05]\n"," [7.87261160e-06]\n"," [1.92659172e-05]\n"," [9.87913609e-06]\n"," [7.28461464e-06]\n"," [1.80766787e-04]\n"," [6.62466118e-05]\n"," [9.61195110e-05]\n"," [1.61346572e-04]\n"," [1.47934130e-04]\n"," [8.21664435e-06]\n"," [5.26740114e-05]\n"," [9.76586816e-05]\n"," [1.29292166e-05]\n"," [3.04130808e-05]\n"," [4.24479913e-06]\n"," [1.29322972e-04]\n"," [3.94009330e-05]\n"," [9.24285359e-06]\n"," [2.29123427e-04]\n"," [5.09925703e-05]\n"," [3.57267418e-05]\n"," [2.33253631e-05]\n"," [7.56232157e-06]\n"," [1.51037912e-05]\n"," [6.26973415e-05]\n"," [7.72199201e-06]\n"," [8.29176224e-06]\n"," [7.95786764e-05]\n"," [1.40505203e-04]\n"," [4.17918727e-07]\n"," [5.41228474e-05]\n"," [2.73372600e-04]\n"," [5.05328353e-04]\n"," [7.73561169e-06]\n"," [1.72645901e-04]\n"," [3.36171215e-04]\n"," [9.23299303e-05]\n"," [3.10749529e-05]\n"," [1.48093925e-04]\n"," [1.56584101e-05]\n"," [1.56621958e-04]\n"," [1.39971789e-05]\n"," [7.88135480e-07]\n"," [2.22591028e-04]\n"," [3.02413628e-05]\n"," [1.36409857e-04]\n"," [1.08491963e-06]\n"," [7.57763773e-05]\n"," [7.16326440e-07]\n"," [1.47933079e-05]\n"," [8.78763967e-05]\n"," [8.14238374e-05]\n"," [6.31979710e-05]\n"," [1.36950039e-04]\n"," [1.26488467e-05]\n"," [1.51324502e-05]\n"," [1.91335319e-04]\n"," [4.63621336e-06]\n"," [2.95875434e-05]\n"," [3.40289007e-05]\n"," [6.53238894e-05]\n"," [8.01917340e-05]\n"," [7.30217562e-06]\n"," [3.42303611e-05]\n"," [3.32303644e-05]\n"," [4.00129138e-05]\n"," [3.42299359e-06]\n"," [2.59868939e-05]\n"," [8.13525185e-05]\n"," [2.42567665e-04]\n"," [4.17594565e-05]\n"," [1.72514192e-04]\n"," [4.93713480e-04]\n"," [1.58060022e-04]\n"," [4.64334298e-05]\n"," [1.32742343e-05]\n"," [2.93563964e-04]\n"," [1.49138514e-05]\n"," [5.94705307e-06]\n"," [2.50823596e-05]\n"," [1.01544967e-04]\n"," [3.13755852e-04]\n"," [1.03574775e-05]\n"," [2.28818768e-04]\n"," [2.16326007e-05]\n"," [2.93762314e-05]\n"," [1.01661848e-04]\n"," [3.49675647e-05]\n"," [3.00675201e-05]\n"," [5.51382109e-05]\n"," [1.72813074e-04]\n"," [4.71203603e-05]\n"," [2.59914232e-05]\n"," [3.19907558e-05]\n"," [2.54277675e-05]\n"," [7.08882944e-05]\n"," [2.49083096e-04]\n"," [1.37107372e-05]\n"," [7.99591271e-06]\n"," [1.75372959e-04]\n"," [6.08117298e-05]\n"," [9.96931067e-06]\n"," [1.59999254e-05]\n"," [2.40342274e-06]\n"," [1.81758180e-04]\n"," [6.04090856e-05]\n"," [7.71703708e-05]\n"," [2.03766467e-05]\n"," [1.84783294e-05]\n"," [1.55460250e-04]\n"," [1.46891421e-06]\n"," [3.55191660e-05]\n"," [4.37998679e-05]\n"," [1.48542977e-05]\n"," [6.50681841e-06]\n"," [6.10922871e-05]\n"," [2.48184233e-06]\n"," [1.00919979e-05]\n"," [4.35217626e-05]\n"," [1.41736541e-06]\n"," [9.65821018e-05]\n"," [9.70275323e-06]\n"," [3.01900618e-05]\n"," [2.04773009e-04]\n"," [3.17187232e-06]\n"," [7.92563660e-05]\n"," [4.26774477e-06]\n"," [3.05905291e-06]\n"," [1.90669889e-05]\n"," [1.93786564e-05]\n"," [4.09905115e-05]\n"," [1.60538781e-04]\n"," [1.01473022e-04]]\n","tensor: seq2seq/decoder/attention/W1/bias/.ATTRIBUTES/VARIABLE_VALUE (float32) [256]\n","[-3.05228354e-03 -3.02117993e-03 -4.62101633e-03  9.85390943e-06\n"," -1.68502168e-03 -1.68979936e-03 -2.19116360e-03  3.07490351e-03\n"," -2.44252803e-03  4.27684700e-03  3.01306904e-03 -4.68886876e-03\n"," -1.18968287e-03  1.08689209e-03 -4.73748602e-04 -2.90214387e-03\n"," -3.08921421e-03  2.33202451e-03  3.06306337e-03  2.75777886e-03\n","  5.20274800e-04 -2.77410238e-03 -8.96573416e-04 -3.22480174e-03\n"," -1.93662290e-03 -3.82645871e-03  2.48937914e-03 -6.93122798e-04\n"," -3.14104557e-03  3.05914180e-03 -3.00413114e-03  1.29027036e-03\n"," -3.89312021e-03  3.17882258e-03  5.46023948e-05  9.88271087e-04\n","  3.08670988e-03 -1.73652009e-03  3.19972611e-03 -3.16154538e-03\n","  2.88651814e-03  5.42848022e-04 -2.85060168e-03 -1.10833673e-03\n","  2.87689734e-03  3.33663402e-03  3.37005709e-03  1.57352979e-03\n","  5.35045110e-04 -3.07138450e-03  3.95977491e-04  8.84160516e-04\n","  5.49488992e-04 -1.89869537e-03 -2.78603472e-03 -7.73943379e-04\n"," -1.15296012e-03  2.97883642e-03 -1.47164415e-03 -3.11430404e-03\n"," -3.03126313e-03 -2.78254575e-03 -3.00039374e-03 -1.35891489e-03\n","  2.07274873e-03  2.85783899e-03 -2.83545512e-03  2.10957834e-03\n"," -3.62410746e-03 -6.26021065e-04 -1.83293177e-03  3.14772502e-03\n","  3.03346268e-03  2.14892277e-03 -1.55070925e-03 -2.81823636e-03\n"," -3.21354950e-04  3.08463606e-03 -3.54118412e-04  2.11717212e-03\n"," -4.63801622e-03  3.13435635e-03 -3.45237018e-03 -2.97817239e-03\n"," -3.39923613e-03  2.93404912e-03  7.08762032e-04 -1.56649866e-03\n"," -2.79930164e-03  1.02804636e-03  3.54009937e-03  4.22166166e-04\n","  4.59966343e-03  2.82304455e-03 -3.40340612e-03  1.13932462e-03\n","  1.37626764e-03 -2.80968193e-03 -2.40858225e-03  2.87721818e-03\n","  9.67534666e-04  1.25416060e-04 -2.35403050e-03  3.08045140e-03\n","  1.25955138e-03  2.94881500e-03  3.08733666e-03 -2.76025385e-03\n","  4.49216226e-03 -2.28371029e-03 -4.13177628e-03  3.22916312e-04\n"," -1.12517946e-03 -3.95407295e-03  1.02971634e-03 -3.60624120e-03\n"," -8.06708413e-04  3.09644919e-03  2.58689467e-03  4.15766705e-03\n"," -2.97332392e-03  3.28011881e-03  2.99637951e-03 -2.94382568e-03\n","  8.89231975e-04  3.55069363e-03 -3.34047899e-03  3.10763111e-03\n"," -1.13286078e-03  3.02995741e-03 -2.41106655e-03 -3.77194490e-03\n"," -2.84460909e-03 -1.93482661e-03  2.98221782e-03  3.59195611e-03\n","  1.94003806e-03  1.96687086e-03  2.99472478e-03 -4.14080499e-03\n","  3.44452169e-03 -3.39320139e-03  4.02972894e-03 -3.53887491e-03\n"," -3.54729732e-03 -2.19626614e-04  2.84688105e-03 -2.84927478e-03\n","  2.07480951e-03  4.37847711e-03  2.91524315e-03  3.16437869e-03\n"," -2.71249167e-03  3.38010723e-03  3.02136503e-03  3.08147073e-03\n","  3.23465350e-03  2.97832512e-03 -3.11547425e-03 -3.58753838e-03\n","  2.00792542e-03  2.92164530e-03 -1.74895732e-03 -2.26019532e-03\n","  3.98226688e-03 -1.04065606e-04 -2.88031762e-03 -4.34010057e-03\n"," -2.86404835e-03 -5.11391833e-03 -2.90609081e-03  2.90566869e-03\n"," -3.98524199e-03 -3.07915919e-03  2.85654282e-03 -3.09776445e-03\n"," -1.82368897e-03  7.47090322e-04  3.34526622e-03 -2.51878076e-03\n"," -2.19779974e-03  1.92854810e-03 -2.85828440e-03  2.93985195e-03\n"," -3.01884906e-03  3.25727230e-03  1.41124974e-03  3.07450094e-03\n"," -3.03998357e-03 -4.74880822e-03  1.28041324e-03 -1.07946631e-03\n"," -2.92008370e-03 -2.45141587e-03  2.98069580e-03 -4.40328754e-03\n"," -2.07623118e-03  3.09387292e-03  4.56890464e-03  3.11140437e-03\n","  2.03724182e-03  3.71274375e-03 -4.37126262e-03 -4.80530225e-03\n","  3.70389735e-03  5.01032686e-04 -3.01201362e-03  1.49045186e-03\n","  2.79716821e-03 -3.65514634e-03 -2.84996070e-03 -3.36502003e-03\n"," -2.95170437e-04 -3.07733333e-03 -3.19888815e-03 -4.48099989e-03\n"," -3.93692264e-03  1.91956293e-03 -3.06961313e-03 -2.90128216e-03\n"," -1.98122021e-03 -2.38009170e-03 -2.99256714e-03 -2.68802582e-03\n"," -3.26831150e-03 -2.50739278e-03 -3.11261858e-04  3.06073064e-03\n"," -2.08703172e-03 -3.03687598e-03 -3.18204379e-03 -1.70374673e-03\n","  1.79542636e-04  4.41851560e-03 -4.06456704e-04 -3.11547541e-03\n"," -3.46423406e-03  2.72288430e-03  2.81411782e-03 -4.19883261e-04\n","  2.95239268e-03 -2.96071847e-03  1.05860014e-03 -3.03523266e-03\n","  1.04338411e-04 -2.15458497e-03  4.33962932e-03  3.80144105e-03\n","  4.33718582e-04 -2.72637978e-03  4.99440962e-03 -2.16628751e-03\n","  3.06761567e-03 -3.14515457e-03  4.33495175e-03 -2.81581585e-03]\n","tensor: seq2seq/decoder/attention/W1/bias/.OPTIMIZER_SLOT/seq2seq/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE (float32) [256]\n","[ 7.06636580e-04  5.13550313e-03  1.07682950e-04 -1.95912344e-05\n","  7.67977544e-05  5.00631053e-04  1.41112660e-05 -2.05499702e-03\n","  6.39651727e-04 -1.07096093e-04 -2.96150357e-03  1.18779880e-03\n","  1.22143101e-04 -6.38045545e-04 -2.06773911e-05  1.60410837e-03\n","  1.43632898e-03 -8.13032559e-04 -1.83815719e-03 -5.27269949e-05\n"," -6.03149587e-04  4.82417550e-03 -2.60924680e-05  1.33715730e-04\n","  1.63815930e-05  1.12530506e-04 -8.17409309e-04 -1.19771292e-04\n","  4.97192726e-04 -4.36586235e-03  1.43058843e-03 -5.97516657e-04\n","  2.18756055e-03 -4.38446132e-03 -8.64231151e-06 -1.20568858e-03\n"," -1.70766527e-03  5.70530887e-04 -3.59132624e-04  2.17414810e-03\n"," -4.63864581e-06  4.01198486e-06  4.00616031e-04 -1.92485182e-04\n"," -4.82394733e-03 -2.51580728e-04 -3.17554986e-05 -1.74730103e-05\n","  8.20887944e-05  3.05050355e-03 -8.85282643e-04 -6.31238159e-04\n"," -3.99436030e-05  9.60514240e-04  3.00935446e-03  5.25488926e-04\n","  1.24489961e-05 -1.74597744e-03 -1.41091605e-05  2.18479661e-03\n","  5.42879920e-04  1.33985945e-04  2.63277837e-03  1.54900699e-05\n"," -1.68276107e-04 -3.39486334e-03  2.24253978e-03 -2.26469510e-05\n","  2.45472370e-03 -5.78656269e-04  4.06684776e-05 -7.63431482e-04\n"," -2.86414707e-03 -4.37962372e-05  2.83201462e-05  1.48423854e-03\n","  6.16999983e-04 -2.96607148e-03  2.83481320e-04 -4.45588143e-04\n","  4.61540127e-04 -6.40244689e-04  2.02765339e-03  3.14615405e-04\n","  2.52337568e-03 -1.14793796e-03 -5.05759126e-05  5.59875276e-04\n","  1.11727265e-03 -1.21250423e-06 -1.18487835e-04 -5.08078898e-04\n"," -2.68180796e-04 -1.95597473e-04  1.00817808e-04 -8.32186139e-04\n"," -9.42030922e-04  1.99952279e-03  9.18446347e-07 -9.05632842e-05\n"," -1.63501918e-05 -3.51911513e-05 -1.03809427e-04 -3.71534581e-04\n"," -4.46871296e-03 -4.89039440e-03 -2.23339442e-03  5.87412855e-03\n"," -8.66800430e-04  1.67062995e-03  5.69837517e-04 -2.65818555e-04\n","  1.83006597e-03  1.93585723e-03  4.69239581e-07  4.23784717e-04\n","  4.06183653e-06 -8.89656483e-04 -2.72571080e-04 -3.04021261e-04\n","  5.75320842e-03 -3.60616134e-04 -3.30898038e-05  6.08279424e-06\n"," -2.44466210e-04 -1.05984145e-04  1.34797097e-04 -2.08842428e-03\n","  6.35134056e-04 -3.72595561e-04  1.26790942e-03  3.75596283e-04\n","  7.08683874e-05  3.46472953e-04 -5.21332677e-03 -1.50816501e-04\n"," -1.53263274e-04  8.72395867e-06 -3.10440152e-03  2.67735403e-03\n"," -5.78379986e-05  1.33540330e-03 -1.85809028e-03  1.78093719e-03\n","  4.51585103e-04 -5.44793729e-04 -3.89149063e-04  2.30200985e-03\n"," -5.70166485e-05 -2.90669384e-04 -3.47988307e-03 -1.60225166e-03\n","  1.23923346e-05 -8.16751388e-04 -2.28265626e-03 -1.30919635e-03\n"," -4.87625279e-04 -3.80979967e-03  1.66816695e-03  3.55024240e-03\n"," -3.07969662e-04 -1.79923931e-03  4.53206361e-04  1.09751163e-04\n"," -2.47985008e-04 -9.77183518e-05  6.16405066e-03  8.23714479e-04\n","  3.51057644e-03  5.93225741e-05  1.60823937e-03  1.55913458e-05\n","  2.43997099e-04  6.12556702e-04 -6.32159063e-05  1.95166643e-03\n","  1.39674157e-04 -1.48552908e-05 -1.31875242e-03  1.97302015e-03\n","  1.73440596e-04 -5.37336418e-05  3.13196820e-03 -6.12116710e-04\n","  3.26469977e-04 -6.74580981e-04 -1.79876952e-04 -1.51983602e-03\n","  1.13369396e-03  2.16631321e-04 -2.17720444e-04 -3.97742806e-05\n","  2.60053319e-03  1.00808172e-03 -9.62023251e-03  5.74595947e-03\n","  4.60744450e-05 -5.09530888e-04 -6.68774708e-04 -7.60766503e-04\n"," -3.29524977e-04 -3.73407267e-04  1.81312207e-03  2.33575143e-03\n"," -4.03101277e-03 -9.29397502e-05  2.45324569e-03 -1.64034554e-05\n"," -6.56675315e-04  1.33639388e-03  7.41142314e-04  1.14339089e-03\n","  2.71437224e-04  8.12415848e-04  2.23726791e-04  8.29546480e-04\n","  2.23667733e-03 -2.48597958e-03  9.51736118e-04  2.68597924e-03\n","  4.27090781e-05  3.76314973e-04  4.93602687e-03  4.15592827e-03\n","  6.59187266e-04  1.94567619e-04 -3.79622907e-05 -2.80870404e-03\n","  9.41343955e-04  3.31921177e-03  9.45066742e-04  7.95107990e-05\n","  6.48672751e-04 -1.09524241e-04  3.49765673e-04  1.05650199e-03\n","  3.84470011e-04 -1.37654788e-04 -1.99407293e-03  1.78877628e-04\n"," -2.92263663e-04  1.08894752e-03  1.91909523e-04  2.94010178e-03\n","  2.60048400e-04  3.28326423e-05 -2.60031247e-03 -4.17033561e-06\n"," -1.95740722e-04  3.49010916e-05 -7.41013355e-05  3.71160859e-05\n"," -1.89311875e-04  4.74338769e-04 -7.45017314e-04  6.33833915e-05]\n","tensor: seq2seq/decoder/attention/W1/bias/.OPTIMIZER_SLOT/seq2seq/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE (float32) [256]\n","[2.82758048e-08 1.41084047e-06 5.46933887e-10 1.24335005e-08\n"," 2.12315276e-09 1.43700456e-08 1.13655929e-09 2.54891575e-07\n"," 6.54920100e-08 1.26580091e-09 4.90938760e-07 8.89238905e-08\n"," 1.87534788e-08 3.48718387e-08 3.00881195e-11 1.74814616e-07\n"," 1.12201562e-07 3.62276644e-08 1.82114533e-07 2.02228034e-09\n"," 4.18745323e-08 1.32328705e-06 7.05520864e-10 1.37442147e-09\n"," 1.60079224e-11 4.66252648e-10 4.82261129e-08 3.50543630e-08\n"," 3.17910498e-08 1.04390551e-06 1.17898452e-07 3.76926046e-08\n"," 2.80683878e-07 1.07066751e-06 2.69112458e-11 9.43836866e-08\n"," 1.55562134e-07 1.76039823e-08 7.16094517e-09 2.92599196e-07\n"," 4.63858996e-09 7.92467064e-11 8.42046521e-09 2.90372992e-09\n"," 1.27174189e-06 4.06420453e-09 2.42237369e-10 3.13988627e-11\n"," 2.89862321e-08 4.74019402e-07 1.09031845e-07 3.20652660e-08\n"," 7.72849840e-10 5.88122724e-08 5.46935894e-07 2.67164726e-08\n"," 3.06901476e-10 1.63059283e-07 3.70741882e-10 2.80201448e-07\n"," 1.96345500e-08 3.46724116e-09 4.29924114e-07 2.62497975e-11\n"," 2.12481832e-09 6.32236095e-07 2.81199135e-07 1.33817749e-10\n"," 3.63863251e-07 3.29196972e-08 5.49708890e-10 2.88697120e-08\n"," 4.62451993e-07 1.52562921e-10 2.04842969e-08 1.22096367e-07\n"," 2.06819717e-08 5.11912447e-07 6.68968347e-09 1.71303274e-08\n"," 1.63223728e-08 2.64115005e-08 2.43774281e-07 1.02174260e-08\n"," 3.65108946e-07 7.01621659e-08 2.25269539e-10 4.32691323e-08\n"," 7.11235444e-08 1.29219396e-11 8.06018141e-10 3.91462613e-08\n"," 3.79820353e-09 3.08209236e-09 5.80819504e-10 4.46219275e-08\n"," 7.34812673e-08 2.51191551e-07 8.02932547e-12 7.56550378e-10\n"," 2.61704991e-10 1.47640081e-10 4.12638723e-09 1.03646380e-08\n"," 1.32611444e-06 1.31698391e-06 2.70423982e-07 2.23585039e-06\n"," 4.43977548e-08 1.91553170e-07 1.83359479e-08 4.71954955e-08\n"," 2.01435938e-07 2.07109565e-07 1.19789649e-13 1.08477760e-08\n"," 8.62457241e-13 4.65467984e-08 4.22548396e-09 5.67836711e-09\n"," 1.78944413e-06 5.29704680e-09 5.06762965e-11 2.24255743e-08\n"," 4.10564160e-09 1.27171873e-09 7.99025346e-10 2.39873316e-07\n"," 2.31005259e-08 1.46766350e-08 1.30258982e-07 8.68464056e-09\n"," 6.51130649e-10 1.30067903e-08 1.38659709e-06 1.60328428e-09\n"," 3.33701933e-09 1.05402254e-09 5.36848745e-07 3.94088943e-07\n"," 4.79781159e-10 9.80047332e-08 2.09605957e-07 1.82613832e-07\n"," 1.28967423e-08 4.42085444e-08 1.16680532e-08 2.94437939e-07\n"," 2.21426225e-10 6.31042951e-09 6.51895050e-07 1.49770813e-07\n"," 1.44458639e-10 3.93143011e-08 2.65201891e-07 8.97463366e-08\n"," 1.15939400e-08 7.97801988e-07 1.40755034e-07 7.42691213e-07\n"," 6.10150330e-09 1.74710351e-07 1.23103217e-08 7.68246133e-10\n"," 1.13872556e-08 2.82532664e-09 2.09678569e-06 5.16460226e-08\n"," 6.90243894e-07 1.73210515e-10 1.26548272e-07 9.00867103e-10\n"," 3.54031471e-09 2.02321910e-08 3.23051003e-10 1.86101332e-07\n"," 1.82410407e-08 1.63859215e-09 1.00030682e-07 3.73827874e-07\n"," 2.25276597e-09 3.27233662e-09 5.40163626e-07 2.41714204e-08\n"," 6.90516089e-09 2.52378314e-08 4.43011849e-09 1.27690413e-07\n"," 7.91229482e-08 2.24076757e-09 3.70919828e-08 2.36556530e-09\n"," 3.69213637e-07 7.36193115e-08 5.19441892e-06 2.08568304e-06\n"," 6.53712862e-10 1.68561503e-08 2.72156448e-08 3.04683638e-08\n"," 2.12993392e-08 6.98596603e-09 2.12904396e-07 2.96522330e-07\n"," 9.73113288e-07 4.09772838e-09 2.76680481e-07 2.69563434e-11\n"," 3.73795679e-08 9.68994840e-08 3.90358785e-08 7.24973432e-08\n"," 1.15020571e-08 3.40662716e-08 2.26611818e-09 5.00601125e-08\n"," 3.16977804e-07 4.76718185e-07 4.62572771e-08 3.69740832e-07\n"," 3.13829907e-10 9.58858237e-09 1.24268092e-06 9.90538297e-07\n"," 3.02518188e-08 6.75881395e-09 3.68422265e-10 4.22917793e-07\n"," 5.78320929e-08 5.89527588e-07 4.75817323e-08 1.10665921e-09\n"," 8.48983106e-08 6.68965272e-10 1.37616425e-08 6.25625347e-08\n"," 1.04313926e-08 2.30832176e-09 2.24614951e-07 3.57964347e-09\n"," 6.86114898e-09 5.65654794e-08 4.66384442e-09 4.70779213e-07\n"," 3.44528068e-08 3.42649131e-10 3.82470205e-07 1.55324690e-12\n"," 5.26326849e-09 1.07527942e-09 3.10822479e-10 3.06689368e-10\n"," 1.93676675e-09 1.06606350e-08 2.83995121e-08 3.61371238e-10]\n","tensor: seq2seq/decoder/attention/W1/kernel/.ATTRIBUTES/VARIABLE_VALUE (float32) [256, 256]\n","[[-0.09427899 -0.02543069 -0.03696447 ... -0.02983958  0.0221182\n","   0.03979157]\n"," [ 0.08730321  0.05605498  0.01496329 ... -0.01951797  0.04821351\n","   0.03517429]\n"," [ 0.01322762 -0.07416208 -0.06132892 ...  0.03473305 -0.01361082\n","   0.00520211]\n"," ...\n"," [-0.09440296  0.04988842  0.01900186 ...  0.00830345  0.06108315\n","   0.09417544]\n"," [-0.04402805 -0.02260251  0.03854781 ... -0.01874013 -0.01635279\n","   0.10265432]\n"," [ 0.0493325  -0.06967657 -0.08500346 ... -0.07113183  0.08260353\n","  -0.06217065]]\n","tensor: seq2seq/decoder/attention/W1/kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE (float32) [256, 256]\n","[[ 2.1544263e-04  1.4991158e-04 -1.5974895e-04 ...  1.6974630e-04\n","  -3.6918922e-04  1.8546396e-05]\n"," [-4.4469978e-04 -1.0684140e-03  3.2444540e-04 ... -4.4780507e-04\n","   9.2755572e-04 -5.3270607e-05]\n"," [-1.6498844e-03 -1.8610758e-03  1.3353003e-03 ... -1.5173758e-03\n","   3.2684889e-03 -1.7288454e-04]\n"," ...\n"," [ 1.3609476e-03  1.8321674e-03 -1.0616574e-03 ...  1.2526563e-03\n","  -2.6762013e-03  1.4227738e-04]\n"," [ 2.3619917e-03  3.6037343e-03 -1.8016531e-03 ...  2.1833063e-03\n","  -4.6423692e-03  2.5072100e-04]\n"," [-2.4653794e-03 -4.1943500e-03  1.8014784e-03 ... -2.2455372e-03\n","   4.7442717e-03 -2.5839536e-04]]\n","tensor: seq2seq/decoder/attention/W1/kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE (float32) [256, 256]\n","[[1.08933014e-08 2.59046757e-08 6.41008491e-09 ... 9.49044754e-09\n","  4.23540634e-08 1.25079280e-10]\n"," [2.08798916e-08 9.09308540e-08 1.15298446e-08 ... 1.91903275e-08\n","  8.59834941e-08 2.86223045e-10]\n"," [1.46979190e-07 2.00060725e-07 9.87661508e-08 ... 1.33180734e-07\n","  5.98937049e-07 1.74229675e-09]\n"," ...\n"," [1.01832576e-07 1.99484660e-07 6.30985113e-08 ... 9.12989080e-08\n","  4.06118659e-07 1.17909260e-09]\n"," [2.84915160e-07 7.06014816e-07 1.70101686e-07 ... 2.55904126e-07\n","  1.13626459e-06 3.37162032e-09]\n"," [3.17585773e-07 9.67285246e-07 1.73515474e-07 ... 2.74750647e-07\n","  1.20655500e-06 3.62670827e-09]]\n","tensor: seq2seq/decoder/attention/W2/bias/.ATTRIBUTES/VARIABLE_VALUE (float32) [256]\n","[-3.0522817e-03 -3.0211802e-03 -4.6210191e-03  9.8683486e-06\n"," -1.6850163e-03 -1.6897984e-03 -2.1911610e-03  3.0749147e-03\n"," -2.4425301e-03  4.2768423e-03  3.0130688e-03 -4.6888697e-03\n"," -1.1896767e-03  1.0868781e-03 -4.7374313e-04 -2.9021439e-03\n"," -3.0892147e-03  2.3320394e-03  3.0630624e-03  2.7578408e-03\n","  5.2027660e-04 -2.7741049e-03 -8.9658936e-04 -3.2247852e-03\n"," -1.9366241e-03 -3.8264231e-03  2.4893554e-03 -6.9313153e-04\n"," -3.1411210e-03  3.0591544e-03 -3.0041314e-03  1.2902794e-03\n"," -3.8931493e-03  3.1788265e-03  5.4537290e-05  9.8827900e-04\n","  3.0867103e-03 -1.7365252e-03  3.1997252e-03 -3.1615444e-03\n","  2.8865244e-03  5.4281123e-04 -2.8505982e-03 -1.1083365e-03\n","  2.8768978e-03  3.3366363e-03  3.3700750e-03  1.5735393e-03\n","  5.3503847e-04 -3.0713854e-03  3.9597438e-04  8.8415958e-04\n","  5.4951839e-04 -1.8986585e-03 -2.7860310e-03 -7.7394198e-04\n"," -1.1529151e-03  2.9788297e-03 -1.4716368e-03 -3.1143322e-03\n"," -3.0312627e-03 -2.7825460e-03 -3.0003923e-03 -1.3588781e-03\n","  2.0727147e-03  2.8578376e-03 -2.8354544e-03  2.1095758e-03\n"," -3.6241470e-03 -6.2603259e-04 -1.8329091e-03  3.1477234e-03\n","  3.0334368e-03  2.1489114e-03 -1.5507040e-03 -2.8182382e-03\n"," -3.2137736e-04  3.0846354e-03 -3.5408692e-04  2.1171616e-03\n"," -4.6380125e-03  3.1343573e-03 -3.4523874e-03 -2.9781857e-03\n"," -3.3992231e-03  2.9340545e-03  7.0887798e-04 -1.5664878e-03\n"," -2.7993089e-03  1.0280376e-03  3.5400959e-03  4.2217560e-04\n","  4.5996620e-03  2.8230425e-03 -3.4034092e-03  1.1392920e-03\n","  1.3762930e-03 -2.8096871e-03 -2.4086458e-03  2.8772163e-03\n","  9.6759771e-04  1.2532208e-04 -2.3540258e-03  3.0804698e-03\n","  1.2595389e-03  2.9488155e-03  3.0873376e-03 -2.7602580e-03\n","  4.4921576e-03 -2.2837026e-03 -4.1317265e-03  3.2292929e-04\n"," -1.1251848e-03 -3.9539654e-03  1.0297957e-03 -3.6062361e-03\n"," -8.0669287e-04  3.0964441e-03  2.5868947e-03  4.1576554e-03\n"," -2.9733237e-03  3.2801195e-03  2.9963595e-03 -2.9438476e-03\n","  8.8905304e-04  3.5505826e-03 -3.3404783e-03  3.1076297e-03\n"," -1.1328561e-03  3.0299672e-03 -2.4110752e-03 -3.7719444e-03\n"," -2.8446058e-03 -1.9348213e-03  2.9822183e-03  3.5918923e-03\n","  1.9400424e-03  1.9669705e-03  2.9947241e-03 -4.1408334e-03\n","  3.4445503e-03 -3.3932063e-03  4.0297545e-03 -3.5389173e-03\n"," -3.5473232e-03 -2.1973663e-04  2.8468780e-03 -2.8492720e-03\n","  2.0748032e-03  4.3784841e-03  2.9152429e-03  3.1643896e-03\n"," -2.7124765e-03  3.3801156e-03  3.0213648e-03  3.0814707e-03\n","  3.2346530e-03  2.9783256e-03 -3.1154726e-03 -3.5875447e-03\n","  2.0079068e-03  2.9216446e-03 -1.7489456e-03 -2.2601967e-03\n","  3.9822534e-03 -1.0409043e-04 -2.8803190e-03 -4.3401024e-03\n"," -2.8640490e-03 -5.1139379e-03 -2.9060859e-03  2.9056207e-03\n"," -3.9852280e-03 -3.0791564e-03  2.8565514e-03 -3.0977640e-03\n"," -1.8236872e-03  7.4707408e-04  3.3452462e-03 -2.5187803e-03\n"," -2.1978540e-03  1.9285431e-03 -2.8582842e-03  2.9398515e-03\n"," -3.0188500e-03  3.2572888e-03  1.4112786e-03  3.0745030e-03\n"," -3.0399840e-03 -4.7488171e-03  1.2804114e-03 -1.0794700e-03\n"," -2.9200816e-03 -2.4514061e-03  2.9806960e-03 -4.4032871e-03\n"," -2.0762400e-03  3.0938734e-03  4.5689074e-03  3.1114048e-03\n","  2.0372444e-03  3.7127207e-03 -4.3712710e-03 -4.8053013e-03\n","  3.7038501e-03  5.0100952e-04 -3.0120127e-03  1.4904742e-03\n","  2.7971687e-03 -3.6552085e-03 -2.8499612e-03 -3.3650633e-03\n"," -2.9518141e-04 -3.0773350e-03 -3.1988760e-03 -4.4809976e-03\n"," -3.9369334e-03  1.9195720e-03 -3.0696124e-03 -2.9012812e-03\n"," -1.9812346e-03 -2.3801413e-03 -2.9925660e-03 -2.6880247e-03\n"," -3.2683143e-03 -2.5073984e-03 -3.1127286e-04  3.0607297e-03\n"," -2.0870101e-03 -3.0368769e-03 -3.1820424e-03 -1.7037295e-03\n","  1.7951065e-04  4.4184984e-03 -4.0645956e-04 -3.1154747e-03\n"," -3.4642336e-03  2.7228647e-03  2.8141169e-03 -4.1987473e-04\n","  2.9523976e-03 -2.9607187e-03  1.0586093e-03 -3.0352331e-03\n","  1.0434694e-04 -2.1545829e-03  4.3396214e-03  3.8014213e-03\n","  4.3370310e-04 -2.7262645e-03  4.9944050e-03 -2.1663040e-03\n","  3.0676157e-03 -3.1451560e-03  4.3349606e-03 -2.8158172e-03]\n","tensor: seq2seq/decoder/attention/W2/bias/.OPTIMIZER_SLOT/seq2seq/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE (float32) [256]\n","[ 7.06635416e-04  5.13549941e-03  1.07683452e-04 -1.95922185e-05\n","  7.67972087e-05  5.00631228e-04  1.41112878e-05 -2.05499725e-03\n","  6.39655278e-04 -1.07098334e-04 -2.96150451e-03  1.18779833e-03\n","  1.22141268e-04 -6.38044730e-04 -2.06774766e-05  1.60410663e-03\n","  1.43632526e-03 -8.13035527e-04 -1.83815486e-03 -5.27278171e-05\n"," -6.03149587e-04  4.82417597e-03 -2.60930701e-05  1.33715279e-04\n","  1.63815930e-05  1.12529524e-04 -8.17406224e-04 -1.19769189e-04\n","  4.97192319e-04 -4.36585676e-03  1.43058656e-03 -5.97517414e-04\n","  2.18755659e-03 -4.38445760e-03 -8.64199319e-06 -1.20568892e-03\n"," -1.70766597e-03  5.70530479e-04 -3.59132478e-04  2.17414810e-03\n"," -4.63812376e-06  4.01240459e-06  4.00616729e-04 -1.92484600e-04\n"," -4.82394546e-03 -2.51579855e-04 -3.17567719e-05 -1.74729485e-05\n","  8.20904170e-05  3.05050542e-03 -8.85281654e-04 -6.31240255e-04\n"," -3.99446544e-05  9.60512261e-04  3.00935679e-03  5.25489158e-04\n","  1.24477829e-05 -1.74597278e-03 -1.41096252e-05  2.18479708e-03\n","  5.42880618e-04  1.33985988e-04  2.63278186e-03  1.54900445e-05\n"," -1.68275583e-04 -3.39486240e-03  2.24254001e-03 -2.26467637e-05\n","  2.45472393e-03 -5.78657608e-04  4.06669642e-05 -7.63430900e-04\n"," -2.86414567e-03 -4.37963572e-05  2.83184672e-05  1.48423784e-03\n","  6.17002137e-04 -2.96607031e-03  2.83481699e-04 -4.45587357e-04\n","  4.61538264e-04 -6.40246319e-04  2.02765595e-03  3.14615085e-04\n","  2.52337707e-03 -1.14794041e-03 -5.05768912e-05  5.59874519e-04\n","  1.11727405e-03 -1.21242158e-06 -1.18487915e-04 -5.08080935e-04\n"," -2.68180534e-04 -1.95597037e-04  1.00817793e-04 -8.32184509e-04\n"," -9.42033774e-04  1.99952582e-03  9.19059005e-07 -9.05641427e-05\n"," -1.63510158e-05 -3.51906565e-05 -1.03809616e-04 -3.71534756e-04\n"," -4.46870970e-03 -4.89039579e-03 -2.23339465e-03  5.87412808e-03\n"," -8.66801187e-04  1.67062983e-03  5.69835422e-04 -2.65821349e-04\n","  1.83006644e-03  1.93585712e-03  4.69220936e-07  4.23785124e-04\n","  4.06183472e-06 -8.89656774e-04 -2.72571022e-04 -3.04021931e-04\n","  5.75320702e-03 -3.60616541e-04 -3.30897456e-05  6.08556775e-06\n"," -2.44464871e-04 -1.05983127e-04  1.34797287e-04 -2.08842289e-03\n","  6.35135337e-04 -3.72595969e-04  1.26791175e-03  3.75595904e-04\n","  7.08681910e-05  3.46472545e-04 -5.21332445e-03 -1.50815758e-04\n"," -1.53263987e-04  8.71991597e-06 -3.10440455e-03  2.67735100e-03\n"," -5.78392501e-05  1.33540540e-03 -1.85808912e-03  1.78093580e-03\n","  4.51585744e-04 -5.44792216e-04 -3.89150198e-04  2.30201078e-03\n"," -5.70171833e-05 -2.90667929e-04 -3.47988680e-03 -1.60225120e-03\n","  1.23903219e-05 -8.16751504e-04 -2.28265626e-03 -1.30919728e-03\n"," -4.87625919e-04 -3.80980014e-03  1.66816614e-03  3.55024217e-03\n"," -3.07970593e-04 -1.79923943e-03  4.53205867e-04  1.09750974e-04\n"," -2.47985561e-04 -9.77173549e-05  6.16405066e-03  8.23714596e-04\n","  3.51057900e-03  5.93225595e-05  1.60824088e-03  1.55927573e-05\n","  2.43996838e-04  6.12556178e-04 -6.32159063e-05  1.95166515e-03\n","  1.39676573e-04 -1.48546997e-05 -1.31875323e-03  1.97302294e-03\n","  1.73443186e-04 -5.37337182e-05  3.13197123e-03 -6.12117059e-04\n","  3.26470239e-04 -6.74579875e-04 -1.79879135e-04 -1.51983509e-03\n","  1.13369257e-03  2.16631888e-04 -2.17720735e-04 -3.97754011e-05\n","  2.60053203e-03  1.00808032e-03 -9.62022599e-03  5.74595947e-03\n","  4.60749616e-05 -5.09530306e-04 -6.68776280e-04 -7.60766445e-04\n"," -3.29526025e-04 -3.73405375e-04  1.81312521e-03  2.33574957e-03\n"," -4.03101183e-03 -9.29388989e-05  2.45324289e-03 -1.64035191e-05\n"," -6.56674209e-04  1.33639388e-03  7.41144991e-04  1.14339078e-03\n","  2.71437922e-04  8.12416256e-04  2.23725874e-04  8.29546421e-04\n","  2.23667757e-03 -2.48597912e-03  9.51735536e-04  2.68597924e-03\n","  4.27091181e-05  3.76318319e-04  4.93603153e-03  4.15592594e-03\n","  6.59186800e-04  1.94569075e-04 -3.79620760e-05 -2.80870544e-03\n","  9.41344653e-04  3.31921247e-03  9.45066218e-04  7.95105443e-05\n","  6.48671237e-04 -1.09526314e-04  3.49765323e-04  1.05650187e-03\n","  3.84469808e-04 -1.37655748e-04 -1.99407316e-03  1.78879156e-04\n"," -2.92265438e-04  1.08894752e-03  1.91908883e-04  2.94009876e-03\n","  2.60046305e-04  3.28323658e-05 -2.60031223e-03 -4.17035881e-06\n"," -1.95740387e-04  3.48997892e-05 -7.41004769e-05  3.71166825e-05\n"," -1.89311831e-04  4.74337721e-04 -7.45014870e-04  6.33831660e-05]\n","tensor: seq2seq/decoder/attention/W2/bias/.OPTIMIZER_SLOT/seq2seq/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE (float32) [256]\n","[2.82757355e-08 1.41083808e-06 5.46940493e-10 1.24335209e-08\n"," 2.12314366e-09 1.43700518e-08 1.13656962e-09 2.54891575e-07\n"," 6.54925429e-08 1.26583299e-09 4.90939044e-07 8.89238976e-08\n"," 1.87533029e-08 3.48718103e-08 3.00877552e-11 1.74814204e-07\n"," 1.12201292e-07 3.62278669e-08 1.82114135e-07 2.02229500e-09\n"," 4.18744897e-08 1.32328648e-06 7.05489334e-10 1.37442502e-09\n"," 1.60079085e-11 4.66239047e-10 4.82258855e-08 3.50542315e-08\n"," 3.17909503e-08 1.04390335e-06 1.17898146e-07 3.76925158e-08\n"," 2.80683565e-07 1.07066649e-06 2.69119605e-11 9.43835516e-08\n"," 1.55562233e-07 1.76039379e-08 7.16094339e-09 2.92599196e-07\n"," 4.63854954e-09 7.92471436e-11 8.42049896e-09 2.90371038e-09\n"," 1.27174110e-06 4.06417344e-09 2.42253162e-10 3.13985678e-11\n"," 2.89862552e-08 4.74019714e-07 1.09032122e-07 3.20651914e-08\n"," 7.72825248e-10 5.88121196e-08 5.46937144e-07 2.67163323e-08\n"," 3.06899894e-10 1.63058886e-07 3.70735054e-10 2.80201277e-07\n"," 1.96345997e-08 3.46723694e-09 4.29925137e-07 2.62500299e-11\n"," 2.12481122e-09 6.32236095e-07 2.81199306e-07 1.33815806e-10\n"," 3.63863165e-07 3.29197682e-08 5.49692014e-10 2.88696658e-08\n"," 4.62451595e-07 1.52565086e-10 2.04842294e-08 1.22096168e-07\n"," 2.06820960e-08 5.11912333e-07 6.68978783e-09 1.71303931e-08\n"," 1.63223000e-08 2.64116249e-08 2.43774736e-07 1.02174340e-08\n"," 3.65109287e-07 7.01623648e-08 2.25262350e-10 4.32694840e-08\n"," 7.11236154e-08 1.29218511e-11 8.06019806e-10 3.91461654e-08\n"," 3.79819554e-09 3.08208259e-09 5.80815729e-10 4.46218564e-08\n"," 7.34810754e-08 2.51192063e-07 8.03015727e-12 7.56566754e-10\n"," 2.61695970e-10 1.47642981e-10 4.12634993e-09 1.03646123e-08\n"," 1.32611410e-06 1.31698391e-06 2.70423840e-07 2.23584971e-06\n"," 4.43979182e-08 1.91553198e-07 1.83358608e-08 4.71955666e-08\n"," 2.01436023e-07 2.07109665e-07 1.19789148e-13 1.08477964e-08\n"," 8.62457837e-13 4.65468801e-08 4.22548396e-09 5.67839376e-09\n"," 1.78944333e-06 5.29705702e-09 5.06762410e-11 2.24257359e-08\n"," 4.10566603e-09 1.27169530e-09 7.99027344e-10 2.39873117e-07\n"," 2.31005348e-08 1.46766777e-08 1.30259025e-07 8.68462902e-09\n"," 6.51129206e-10 1.30067921e-08 1.38659561e-06 1.60327651e-09\n"," 3.33703554e-09 1.05405651e-09 5.36850223e-07 3.94088090e-07\n"," 4.79795315e-10 9.80049748e-08 2.09605957e-07 1.82613675e-07\n"," 1.28967477e-08 4.42087220e-08 1.16681056e-08 2.94438451e-07\n"," 2.21433205e-10 6.31037489e-09 6.51896300e-07 1.49770784e-07\n"," 1.44444776e-10 3.93143083e-08 2.65201834e-07 8.97464716e-08\n"," 1.15939924e-08 7.97802102e-07 1.40754892e-07 7.42691554e-07\n"," 6.10153306e-09 1.74710337e-07 1.23103012e-08 7.68242525e-10\n"," 1.13872947e-08 2.82534773e-09 2.09678433e-06 5.16461114e-08\n"," 6.90244633e-07 1.73209072e-10 1.26548670e-07 9.00866992e-10\n"," 3.54030805e-09 2.02321928e-08 3.23049643e-10 1.86101133e-07\n"," 1.82412929e-08 1.63857550e-09 1.00030547e-07 3.73829266e-07\n"," 2.25275176e-09 3.27235794e-09 5.40164478e-07 2.41714595e-08\n"," 6.90516977e-09 2.52378278e-08 4.43013537e-09 1.27690242e-07\n"," 7.91227350e-08 2.24078289e-09 3.70920716e-08 2.36555664e-09\n"," 3.69213183e-07 7.36192760e-08 5.19441164e-06 2.08568395e-06\n"," 6.53719801e-10 1.68561183e-08 2.72157425e-08 3.04683496e-08\n"," 2.12993925e-08 6.98591984e-09 2.12905135e-07 2.96522018e-07\n"," 9.73113401e-07 4.09772216e-09 2.76679998e-07 2.69561960e-11\n"," 3.73794222e-08 9.68992708e-08 3.90361201e-08 7.24972367e-08\n"," 1.15019780e-08 3.40662680e-08 2.26612018e-09 5.00601374e-08\n"," 3.16978060e-07 4.76716792e-07 4.62572416e-08 3.69741088e-07\n"," 3.13824577e-10 9.58856639e-09 1.24268422e-06 9.90537274e-07\n"," 3.02517336e-08 6.75887657e-09 3.68423875e-10 4.22918333e-07\n"," 5.78321284e-08 5.89527588e-07 4.75816648e-08 1.10666509e-09\n"," 8.48981685e-08 6.68997469e-10 1.37617526e-08 6.25625205e-08\n"," 1.04314273e-08 2.30836505e-09 2.24615050e-07 3.57965280e-09\n"," 6.86120760e-09 5.65654616e-08 4.66383110e-09 4.70778048e-07\n"," 3.44528779e-08 3.42644885e-10 3.82470375e-07 1.55327021e-12\n"," 5.26328403e-09 1.07524367e-09 3.10816733e-10 3.06690923e-10\n"," 1.93676630e-09 1.06605844e-08 2.83993966e-08 3.61367991e-10]\n","tensor: seq2seq/decoder/attention/W2/kernel/.ATTRIBUTES/VARIABLE_VALUE (float32) [256, 256]\n","[[-0.05225203 -0.04390646  0.03142039 ...  0.0658629   0.08726731\n","   0.08044396]\n"," [ 0.03528217 -0.1033139   0.03283081 ... -0.06773871 -0.07055904\n","   0.08572339]\n"," [ 0.10252726  0.04754439 -0.08843848 ... -0.08450638 -0.06078653\n","   0.05617191]\n"," ...\n"," [-0.04186393 -0.09947865 -0.05726913 ...  0.00299641  0.03449685\n","  -0.04243711]\n"," [ 0.03793099 -0.01703591 -0.03745951 ... -0.00676983 -0.08841439\n","   0.010429  ]\n"," [-0.11064668 -0.10261532 -0.02621551 ... -0.07045384 -0.00071138\n","   0.04328873]]\n","tensor: seq2seq/decoder/attention/W2/kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE (float32) [256, 256]\n","[[ 1.58573457e-04  1.31255621e-03  3.96671312e-05 ...  1.59548654e-04\n","  -2.06144541e-04  9.46771979e-06]\n"," [ 8.81477899e-06  1.14185146e-04  6.44025613e-06 ...  2.71327899e-05\n","  -3.25779438e-05 -2.43506292e-06]\n"," [-1.80768344e-04 -1.53825921e-03 -4.70736231e-05 ... -1.78518414e-04\n","   2.18545334e-04 -1.35630225e-05]\n"," ...\n"," [-9.21546816e-05 -7.41153024e-04 -2.38995362e-05 ... -9.66367443e-05\n","   1.39237658e-04 -4.47667435e-06]\n"," [ 1.65247489e-04  1.40190485e-03  4.32314482e-05 ...  1.67764767e-04\n","  -2.01488787e-04  1.15902249e-05]\n"," [ 6.23465021e-05  4.47577011e-04  1.19114693e-05 ...  4.50509979e-05\n","  -7.19467716e-05  5.49209472e-06]]\n","tensor: seq2seq/decoder/attention/W2/kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE (float32) [256, 256]\n","[[1.58732383e-09 9.38199705e-08 6.70579009e-11 ... 1.08826126e-09\n","  1.96700367e-09 7.23565088e-12]\n"," [6.53471860e-11 3.34949246e-09 2.18686809e-12 ... 4.24258510e-11\n","  7.49487694e-11 1.46924085e-12]\n"," [2.06825668e-09 1.27309477e-07 9.75538123e-11 ... 1.37887557e-09\n","  2.24028462e-09 1.41687695e-11]\n"," ...\n"," [5.08565356e-10 2.79645285e-08 2.20144892e-11 ... 3.62822938e-10\n","  7.96751609e-10 1.82621886e-12]\n"," [1.70048409e-09 1.04138110e-07 7.98024286e-11 ... 1.18784926e-09\n","  1.87544136e-09 1.05322027e-11]\n"," [2.07304937e-10 9.57208091e-09 5.61506137e-12 ... 7.68906952e-11\n","  1.96273109e-10 3.50604723e-12]]\n","tensor: seq2seq/decoder/embedding/embeddings/.ATTRIBUTES/VARIABLE_VALUE (float32) [31814, 300]\n","[[ 0.06910352  0.16359438  0.21404478 ...  0.0174351   0.04612398\n","   0.08113346]\n"," [ 0.28097576  0.14257158  0.00661724 ... -0.06445258  0.291413\n","  -0.04119396]\n"," [ 0.21996681  0.1348594   0.02106686 ... -0.13058513  0.27785984\n","   0.08096611]\n"," ...\n"," [ 0.41804624  0.13103627  0.1268268  ...  0.14072238  0.18222344\n","   0.17184246]\n"," [ 0.6723439   0.13353814  0.12505423 ...  0.10661148  0.3607966\n","   0.29318964]\n"," [ 0.1535453   0.03204642  0.11340024 ... -0.02492948  0.27076766\n","   0.03821345]]\n","tensor: seq2seq/decoder/fc/bias/.ATTRIBUTES/VARIABLE_VALUE (float32) [31814]\n","[ 0.00586207 -0.00597561 -0.00598948 ... -0.00598426  0.00599646\n","  0.0047213 ]\n","tensor: seq2seq/decoder/fc/bias/.OPTIMIZER_SLOT/seq2seq/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE (float32) [31814]\n","[-7.3197472e-01  5.1987520e-04  5.4961565e-04 ...  5.2581070e-04\n"," -1.1033343e+01 -1.9492239e-02]\n","tensor: seq2seq/decoder/fc/bias/.OPTIMIZER_SLOT/seq2seq/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE (float32) [31814]\n","[1.4992667e-02 7.4657960e-09 8.2467313e-09 ... 7.5836670e-09 3.3577793e+00\n"," 1.4920653e-05]\n","tensor: seq2seq/decoder/fc/kernel/.ATTRIBUTES/VARIABLE_VALUE (float32) [256, 31814]\n","[[-0.00289336 -0.01284098 -0.00358186 ...  0.00614212  0.01203807\n","  -0.00806547]\n"," [ 0.00192812  0.0004474   0.00376242 ...  0.00055546  0.00304754\n","  -0.0085126 ]\n"," [-0.00890514  0.00903417  0.01888247 ...  0.00782655 -0.01352124\n","   0.00600443]\n"," ...\n"," [-0.01878     0.01427264  0.00686924 ...  0.014392   -0.00876762\n","   0.00787659]\n"," [ 0.01892934 -0.01272236 -0.01070601 ...  0.00125461  0.01423496\n","  -0.00889403]\n"," [-0.00676154  0.00667969  0.00612708 ... -0.0090696   0.0038236\n","  -0.00889547]]\n","tensor: seq2seq/decoder/fc/kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE (float32) [256, 31814]\n","[[-2.06815004e-01  1.56575974e-04  1.68955870e-04 ...  1.60113428e-04\n","  -3.55442715e+00 -5.96672529e-03]\n"," [-4.57837358e-02  2.11037350e-05  2.36513897e-05 ...  2.21937553e-05\n","  -2.74027407e-01 -1.51864206e-03]\n"," [ 1.75664425e-01 -1.62003897e-04 -1.74827059e-04 ... -1.65469173e-04\n","   4.08841562e+00  5.14826132e-03]\n"," ...\n"," [ 1.28125697e-01 -1.02719372e-04 -1.11411486e-04 ... -1.05260922e-04\n","   2.46099639e+00  3.35682021e-03]\n"," [-2.09421292e-01  1.63482851e-04  1.76151327e-04 ...  1.66967729e-04\n","  -3.84558272e+00 -6.10164134e-03]\n"," [-2.56785396e-02  5.65996888e-05  6.02360742e-05 ...  5.71483397e-05\n","  -1.68356705e+00 -2.02197861e-03]]\n","tensor: seq2seq/decoder/fc/kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE (float32) [256, 31814]\n","[[1.53507281e-03 7.75670417e-10 9.13390363e-10 ... 8.15985002e-10\n","  3.99795711e-01 1.67816540e-06]\n"," [1.06572043e-04 6.07903519e-11 6.88764254e-11 ... 6.23840632e-11\n","  3.19452845e-02 1.68285439e-07]\n"," [1.13823113e-03 8.14907364e-10 9.59475721e-10 ... 8.55391924e-10\n","  5.05424261e-01 1.46902448e-06]\n"," ...\n"," [7.15976988e-04 3.75587478e-10 4.48143522e-10 ... 3.97389899e-10\n","  2.10776210e-01 4.70343792e-07]\n"," [1.52203662e-03 8.05426448e-10 9.47088963e-10 ... 8.45980452e-10\n","  4.44480121e-01 1.69122234e-06]\n"," [6.14300297e-05 1.10800188e-10 1.22638219e-10 ... 1.11292885e-10\n","  8.86078849e-02 2.17588010e-07]]\n","tensor: seq2seq/decoder/gru/cell/bias/.ATTRIBUTES/VARIABLE_VALUE (float32) [2, 768]\n","[[-0.00529048  0.00419118 -0.00548839 ... -0.0059242   0.00597765\n","   0.00106835]\n"," [-0.00529048  0.00419118 -0.00548839 ... -0.00592169  0.00598501\n","   0.00100029]]\n","tensor: seq2seq/decoder/gru/cell/bias/.OPTIMIZER_SLOT/seq2seq/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE (float32) [2, 768]\n","[[ 0.02101778 -0.0010597   0.01522854 ...  0.04310323 -0.06745147\n","  -0.01798519]\n"," [ 0.02101778 -0.0010597   0.01522854 ...  0.02456401 -0.04440066\n","  -0.00773594]]\n","tensor: seq2seq/decoder/gru/cell/bias/.OPTIMIZER_SLOT/seq2seq/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE (float32) [2, 768]\n","[[1.4550239e-05 1.3019590e-07 7.0160077e-06 ... 5.0986182e-05\n","  1.2977910e-04 1.2778287e-05]\n"," [1.4550239e-05 1.3019590e-07 7.0160077e-06 ... 1.6561853e-05\n","  5.5436631e-05 2.4219526e-06]]\n","tensor: seq2seq/decoder/gru/cell/kernel/.ATTRIBUTES/VARIABLE_VALUE (float32) [556, 768]\n","[[-0.01230646 -0.05327462  0.00098588 ... -0.00477493 -0.0244297\n","  -0.06867949]\n"," [-0.00289748 -0.066365    0.01245419 ... -0.03431584  0.02392953\n","   0.00302668]\n"," [ 0.02443256  0.02247142 -0.04254043 ...  0.03128599 -0.00696844\n","   0.01079919]\n"," ...\n"," [-0.00575252 -0.00396174  0.01373766 ... -0.04572259  0.00317651\n","   0.02533443]\n"," [-0.06722594 -0.05959565 -0.01597443 ...  0.05572648  0.05204026\n","  -0.02549379]\n"," [ 0.06099464  0.04959556 -0.06071252 ... -0.02157296  0.00731313\n","   0.06187247]]\n","tensor: seq2seq/decoder/gru/cell/kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE (float32) [556, 768]\n","[[-3.7753799e-03 -5.9163009e-05 -2.4334050e-03 ... -5.6401542e-03\n","   5.2452236e-03  3.4059645e-03]\n"," [-2.8545533e-03  1.7172397e-05 -1.7615218e-03 ... -4.0502017e-03\n","   3.3414389e-03  2.3899833e-03]\n"," [ 1.4129365e-02 -2.2936217e-04  9.6012838e-03 ...  2.4693413e-02\n","  -3.1475138e-02 -1.2149998e-02]\n"," ...\n"," [ 2.1718538e-03 -1.2723445e-04  1.5632071e-03 ...  4.2397399e-03\n","  -6.4404374e-03 -1.7851761e-03]\n"," [ 6.6561513e-03 -2.6502498e-04  5.0856322e-03 ...  1.2682485e-02\n","  -2.0344734e-02 -5.4952917e-03]\n"," [ 5.4947347e-03 -2.5060802e-04  4.2085997e-03 ...  1.1265863e-02\n","  -1.7223643e-02 -4.4356720e-03]]\n","tensor: seq2seq/decoder/gru/cell/kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE (float32) [556, 768]\n","[[6.9249836e-07 1.8753765e-09 2.8416949e-07 ... 1.6619068e-06\n","  2.0807875e-06 4.9707279e-07]\n"," [5.2659038e-07 1.3715487e-10 2.0913724e-07 ... 1.1597623e-06\n","  1.3119361e-06 3.7133501e-07]\n"," [7.8365338e-06 2.5729543e-09 3.3532433e-06 ... 2.0465048e-05\n","  2.9256486e-05 5.6863669e-06]\n"," ...\n"," [1.5326791e-07 1.3360910e-09 7.3110286e-08 ... 4.9433316e-07\n","  1.2169008e-06 1.2608017e-07]\n"," [1.4352896e-06 1.5312489e-08 7.7178686e-07 ... 4.4316798e-06\n","  1.2341688e-05 1.1458824e-06]\n"," [9.7159273e-07 1.0275351e-08 5.3068442e-07 ... 3.5340265e-06\n","  8.7701919e-06 7.5174722e-07]]\n","tensor: seq2seq/decoder/gru/cell/recurrent_kernel/.ATTRIBUTES/VARIABLE_VALUE (float32) [256, 768]\n","[[-0.05637209 -0.06350962 -0.07011197 ...  0.00137354 -0.01484408\n","  -0.0110873 ]\n"," [-0.01155493  0.03827321 -0.0240338  ... -0.04555493 -0.06128086\n","  -0.04271419]\n"," [ 0.05690157  0.03258771 -0.03548594 ...  0.02437017 -0.03129195\n","  -0.0683976 ]\n"," ...\n"," [ 0.05009095  0.0148093   0.03986526 ... -0.03428806  0.00370919\n","  -0.04983995]\n"," [-0.04107031  0.07550497  0.04923116 ... -0.07430343 -0.01274116\n","   0.00134929]\n"," [-0.020807   -0.03342384 -0.0650024  ... -0.04103204 -0.05045277\n","   0.00951339]]\n","tensor: seq2seq/decoder/gru/cell/recurrent_kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE (float32) [256, 768]\n","[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n","tensor: seq2seq/decoder/gru/cell/recurrent_kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE (float32) [256, 768]\n","[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n","tensor: seq2seq/encoder/embedding/embeddings/.ATTRIBUTES/VARIABLE_VALUE (float32) [31814, 300]\n","[[ 0.06910352  0.16359438  0.21404478 ...  0.0174351   0.04612398\n","   0.08113346]\n"," [ 0.28097576  0.14257158  0.00661724 ... -0.06445258  0.291413\n","  -0.04119396]\n"," [ 0.21996681  0.1348594   0.02106686 ... -0.13058513  0.27785984\n","   0.08096611]\n"," ...\n"," [ 0.41804624  0.13103627  0.1268268  ...  0.14072238  0.18222344\n","   0.17184246]\n"," [ 0.6723439   0.13353814  0.12505423 ...  0.10661148  0.3607966\n","   0.29318964]\n"," [ 0.1535453   0.03204642  0.11340024 ... -0.02492948  0.27076766\n","   0.03821345]]\n","tensor: seq2seq/encoder/gru/cell/bias/.ATTRIBUTES/VARIABLE_VALUE (float32) [2, 768]\n","[[ 0.00458045  0.00218613 -0.00493133 ... -0.00577943 -0.00581946\n","   0.0059578 ]\n"," [ 0.00458045  0.00218613 -0.00493133 ... -0.00579404 -0.00581595\n","   0.00596326]]\n","tensor: seq2seq/encoder/gru/cell/bias/.OPTIMIZER_SLOT/seq2seq/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE (float32) [2, 768]\n","[[-9.7406628e-06  2.5773838e-06  7.1185736e-05 ...  7.3519431e-02\n","   7.8711450e-02 -3.7734941e-02]\n"," [-9.7406628e-06  2.5773838e-06  7.1185736e-05 ...  3.5112750e-02\n","   4.5061424e-02 -2.0494904e-02]]\n","tensor: seq2seq/encoder/gru/cell/bias/.OPTIMIZER_SLOT/seq2seq/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE (float32) [2, 768]\n","[[6.6062095e-12 1.5238864e-11 1.9491293e-10 ... 1.5150500e-04\n","  1.7392186e-04 3.8724727e-05]\n"," [6.6062095e-12 1.5238864e-11 1.9491293e-10 ... 3.4537119e-05\n","  5.6843066e-05 1.1372398e-05]]\n","tensor: seq2seq/encoder/gru/cell/kernel/.ATTRIBUTES/VARIABLE_VALUE (float32) [300, 768]\n","[[ 0.00010573 -0.03459055  0.03684964 ...  0.02070578 -0.02905893\n","  -0.05398331]\n"," [ 0.01404841  0.05874872  0.03585134 ... -0.07880347  0.02208999\n","   0.02720431]\n"," [-0.0157023   0.01251589  0.00993394 ...  0.05168724  0.02794293\n","  -0.03283793]\n"," ...\n"," [-0.02668459  0.0178762  -0.05938098 ... -0.06177766 -0.05898313\n","   0.07393694]\n"," [-0.05957783 -0.05560278 -0.07214747 ... -0.04581691 -0.03660805\n","  -0.05378155]\n"," [-0.03740637  0.05312759  0.01010395 ... -0.02067707 -0.06138381\n","   0.00269121]]\n","tensor: seq2seq/encoder/gru/cell/kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE (float32) [300, 768]\n","[[-1.5528589e-05  4.5449256e-06  4.8613947e-05 ...  4.4382866e-02\n","   3.3061851e-02 -1.7067187e-02]\n"," [-8.7970238e-07 -5.3493086e-08  3.0026190e-06 ...  9.1413762e-03\n","   7.3224087e-03 -3.7324145e-03]\n"," [ 8.7214175e-06  8.1564599e-07 -1.3412849e-06 ...  9.0818200e-03\n","   8.8327331e-03 -4.3575065e-03]\n"," ...\n"," [ 9.2897390e-06  5.6740708e-07  1.3116493e-05 ...  7.1300156e-03\n","   5.5535720e-03 -2.8989129e-03]\n"," [-6.9520274e-06  1.2622966e-06  2.2183012e-05 ...  2.4298156e-02\n","   1.9030526e-02 -9.7223781e-03]\n"," [ 4.2649235e-06 -4.0260804e-07  2.0336061e-05 ...  1.9099435e-02\n","   1.4324855e-02 -7.3341103e-03]]\n","tensor: seq2seq/encoder/gru/cell/kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE (float32) [300, 768]\n","[[1.29436592e-11 6.05689544e-12 1.01118246e-10 ... 5.74097394e-05\n","  3.42165804e-05 8.59891679e-06]\n"," [1.00380988e-12 5.58375178e-13 3.91333407e-12 ... 2.41766020e-06\n","  1.61414187e-06 3.98654322e-07]\n"," [5.28416590e-12 1.19671593e-13 1.52433697e-12 ... 2.32935008e-06\n","  2.14655392e-06 5.09887229e-07]\n"," ...\n"," [5.04174523e-12 8.81548686e-13 1.47299586e-11 ... 1.47388084e-06\n","  9.23478240e-07 2.38611278e-07]\n"," [2.94815301e-12 1.69603220e-12 1.86049266e-11 ... 1.70887870e-05\n","  1.08631048e-05 2.70933924e-06]\n"," [2.09080669e-12 1.17693539e-12 3.27344506e-11 ... 1.06395719e-05\n","  6.38459642e-06 1.58352702e-06]]\n","tensor: seq2seq/encoder/gru/cell/recurrent_kernel/.ATTRIBUTES/VARIABLE_VALUE (float32) [256, 768]\n","[[ 0.0327971   0.01126732  0.05446339 ...  0.0306828  -0.05285752\n","  -0.06926656]\n"," [-0.05443001  0.02303995  0.00880978 ... -0.06707289 -0.0311378\n","  -0.07941647]\n"," [-0.05232441  0.07505627 -0.0275713  ... -0.03116417 -0.07792112\n","   0.03077153]\n"," ...\n"," [ 0.07119856 -0.01583396  0.04004081 ...  0.07649626 -0.04583963\n","  -0.07586285]\n"," [ 0.0579197   0.01285404 -0.04672383 ...  0.01069191  0.04512858\n","   0.0296818 ]\n"," [ 0.05117706 -0.04316569  0.00048328 ...  0.06563671 -0.01184722\n","   0.00781168]]\n","tensor: seq2seq/encoder/gru/cell/recurrent_kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE (float32) [256, 768]\n","[[ 2.1746913e-05 -1.5959311e-06 -6.7742362e-06 ... -4.8580449e-03\n","  -5.4884888e-03  2.2760876e-03]\n"," [ 4.4374340e-07  1.6046355e-08 -3.5981686e-06 ... -3.2908053e-03\n","  -4.8961197e-03  1.9516409e-03]\n"," [-5.2185756e-06  4.7911585e-06  2.6271540e-05 ...  2.0601211e-02\n","   2.2026300e-02 -9.7617013e-03]\n"," ...\n"," [ 2.1352487e-06 -3.3390631e-06 -1.9804893e-05 ... -1.3330526e-02\n","  -1.3681400e-02  6.0936334e-03]\n"," [-2.9294435e-08 -2.9802720e-06 -2.0909725e-05 ... -1.7540930e-02\n","  -1.6866157e-02  7.6481714e-03]\n"," [ 2.9816135e-06  2.6229625e-06  2.0183918e-05 ...  1.4689140e-02\n","   1.3079342e-02 -5.8516115e-03]]\n","tensor: seq2seq/encoder/gru/cell/recurrent_kernel/.OPTIMIZER_SLOT/seq2seq/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE (float32) [256, 768]\n","[[2.3192354e-11 3.3488346e-13 2.0589377e-12 ... 1.1629392e-06\n","  1.4689259e-06 2.6361931e-07]\n"," [1.9226540e-14 8.9927745e-13 8.0134190e-13 ... 8.0803557e-07\n","  1.0513487e-06 1.7210969e-07]\n"," [1.2536223e-12 3.8126663e-12 6.5039842e-11 ... 1.4260808e-05\n","  1.7540280e-05 3.2309335e-06]\n"," ...\n"," [3.6192089e-13 1.7836029e-12 1.4592813e-11 ... 5.9382833e-06\n","  7.0312117e-06 1.2813712e-06]\n"," [1.3425503e-13 1.8965101e-12 1.6713490e-11 ... 9.9510862e-06\n","  1.1119336e-05 2.0609596e-06]\n"," [7.3798991e-13 1.6813981e-12 1.7366183e-11 ... 7.6593014e-06\n","  8.6105792e-06 1.5201086e-06]]\n","tensor: seq2seq/optimizer/beta_1/.ATTRIBUTES/VARIABLE_VALUE (float32) []\n","0.9\n","tensor: seq2seq/optimizer/beta_2/.ATTRIBUTES/VARIABLE_VALUE (float32) []\n","0.999\n","tensor: seq2seq/optimizer/decay/.ATTRIBUTES/VARIABLE_VALUE (float32) []\n","0.0\n","tensor: seq2seq/optimizer/iter/.ATTRIBUTES/VARIABLE_VALUE (int64) []\n","6\n","tensor: seq2seq/optimizer/learning_rate/.ATTRIBUTES/VARIABLE_VALUE (float32) []\n","0.001\n","# Total number of params: 47173612\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XOUeVod0zylj","colab_type":"code","colab":{}},"source":["checkpoint = def_checkpoint(encoder, decoder, optimizer)\n","\n","load_status = checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n","load_status.assert_consumed()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GYJbc8g3ZVGs","colab_type":"code","colab":{}},"source":["decoder.embedding.embeddings"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cAZYWDeXg4GT","colab_type":"code","colab":{}},"source":["import os\n","from tensorflow.python import pywrap_tensorflow\n","# checkpoint_path = os.path.join(model_dir, \"model.ckpt\")\n","checkpoint_path = checkpoint_prefix\n","reader = pywrap_tensorflow.NewCheckpointReader(checkpoint_path)\n","var_to_shape_map = reader.get_variable_to_shape_map()\n","for key in var_to_shape_map:\n","    print(\"\\r\\ntensor_name: \", key, end=' ')\n","    print(reader.get_tensor(key))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M1414MQTFmnm","colab_type":"code","colab":{}},"source":["load_status.assert_existing_objects_matched()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SKqKdFuJPdyb","colab_type":"code","colab":{}},"source":["doc = \"更好机油散热器，问题依然没有解决技师说仪表亮红色机油灯？|车主说|车主说滴滴几声恢复正常。请参考原先提问！|技师说到哪去找。|车主说图片|车主说看到？|技师说领驭？|车主说|车主说感觉行驶一段时间后报警。走走停停报警次数增多。|技师说稍|技师说图片|技师说图片|技师说测量一下标准机油压力，压力低需要进行相应检查维修。|车主说凉车机油压力4|车主说热车才1|技师说热车怠速最低1.3|车主说不了1.3|技师说发动机水温？|车主说水温正常|车主说没有测量温度|技师说水温80度机油压力不到1.3，说明卸压，水温90以上，不到1.3说明散热不好。|车主说好|车主说再试试|车主说两种情况处理？|技师说冷车机油粘度大，压力肯定高|车主说两种情况解决？|技师说水温80度，机油压力灯亮，说明机械方面故障，考虑机油泵，限压阀，机油喷嘴，热车机油压力灯亮，重点考虑机油粘度机油散热器，水箱是否堵塞，机油里加注抗磨剂。\"\n","ts = document_as_tensor(doc)\n","evaluate(encoder, decoder, doc)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b2uj42HKQdEa","colab_type":"code","colab":{}},"source":["ts"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WuCO7RbmiwKa","colab_type":"code","colab":{}},"source":["decoder = UniGruDecoderWithAttention(vocab_tar_size, embedding_dim, working_ds.embedding_matrix, codec_units, BATCH_SIZE)\n","\n","sample_decoder_output, state, attention_weights = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n","                                      sample_hidden, sample_output)\n","decoder.summary()\n","print ('UniGruDecoderWithAttention output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))\n","print ('UniGruDecoderWithAttention state shape: (batch_size, vocab size) {}'.format(state.shape))\n","print ('UniGruDecoderWithAttention attention_weights shape: (batch_size, vocab size) {}'.format(attention_weights.shape))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rc4TTq1CiwKd","colab_type":"code","colab":{}},"source":["attention_layer = BahdanauAttention(10)\n","attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n","attention_layer.summary()\n","\n","print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n","print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sy6bFkRm6HLD","colab_type":"code","colab":{}},"source":["21195*300"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jD2lhiUqiwKf","colab_type":"code","colab":{}},"source":["dataset = tf.data.Dataset.from_tensor_slices((working_ds.train_ids_x, working_ds.train_ids_y)).shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n","\n","example_input_batch, example_target_batch = next(iter(dataset))\n","print(example_input_batch.shape, example_target_batch.shape)\n","print(example_input_batch)\n","\n","encoder = UnidirGruEncoder(vocab_inp_size, embedding_dim, working_ds.embedding_matrix, codec_units, BATCH_SIZE)\n","\n","# sample input\n","sample_hidden = encoder.initialize_hidden_state()\n","sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n","\n","encoder.summary()\n","print ('ThisEncoder input shape: (batch size, sequence length) {}'.format(example_input_batch.shape))\n","print ('ThisEncoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n","print ('ThisEncoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))\n","print(type(encoder.embedding.embeddings))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zfRvfoSPiwKi","colab_type":"code","colab":{}},"source":["# !pip show tensorflow-gpu\n","# tf.__version__\n","# gpus = tf.config.experimental.list_physical_devices('GPU')\n","# print(gpus)\n","# tf.test.is_gpu_available( cuda_only=False, min_cuda_compute_capability=None )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iHF0pFPsiwKk","colab_type":"code","colab":{}},"source":["# -*- coding:utf-8 -*-\n","# Created by Kevin Luo at 2019-12-17\n","import tensorflow as tf\n","\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional\n","from tensorflow.keras.layers import Embedding\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.losses import sparse_categorical_crossentropy\n","\n","\n","def seq2seq(input_length, output_sequence_length, embedding_matrix, vocab_size):\n","    model = Sequential()\n","    model.add(Embedding(input_dim=vocab_size, output_dim=300, weights=[embedding_matrix], trainable=False,\n","                        input_length=input_length))\n","    model.add(Bidirectional(GRU(300, return_sequences=False)))\n","    model.add(Dense(300, activation=\"relu\"))\n","    model.add(RepeatVector(output_sequence_length))\n","    model.add(Bidirectional(GRU(300, return_sequences=True)))\n","    model.add(TimeDistributed(Dense(vocab_size, activation='softmax')))\n","    model.compile(loss=sparse_categorical_crossentropy,\n","                  optimizer=Adam(1e-3))\n","    model.summary()\n","    return model\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VgxgupwLiwKp","colab_type":"code","colab":{}},"source":["print(working_ds.train_df['X'].iloc[4999])\n","\n","working_ds.wv_model.most_similar(positive=['语音'], negative=[])\n","\n","print(working_ds.train_csv)\n","print(working_ds.test_csv)\n","        \n","print(working_ds.train_df.shape)\n","print(working_ds.test_df.shape)\n","print(working_ds.merged_df.shape)\n","        \n","print(working_ds.train_y_max_len)\n","        \n","print(working_ds.X_max_len)\n","\t\t\n","print(working_ds.train_X.shape)\n","print(working_ds.train_Y.shape)\n","print(working_ds.test_X.shape)\n","\n","print(working_ds.train_ids_x.shape)\n","print(working_ds.train_ids_y.shape)\n","print(working_ds.test_ids_x.shape)\n","\t\t\n","print(working_ds.wv_model)\n","\t\t\n","print(len(working_ds.vocab))\n","print(len(working_ds.reverse_vocab))\n","\t\t\n","print(working_ds.embedding_matrix.shape)\n","\n","print(working_ds.train_ids_x.shape)\n","print(working_ds.train_ids_y.shape)\n","print(working_ds.test_ids_x.shape)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6AlXOtZViwKs","colab_type":"code","colab":{}},"source":["basic_s2s_model = seq2seq(working_ds.X_max_len, working_ds.train_y_max_len, working_ds.embedding_matrix, len(working_ds.vocab))\n","\n","basic_s2s_model.fit(working_ds.train_X, working_ds.train_Y, batch_size=32, epochs=1, validation_split=0.2)\n","basic_s2s_model.save(os.path.join(project_root, r'data\\seq2seq_basic_s2s.model'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DqnAN2vCiwKw","colab_type":"code","colab":{}},"source":["working_ds.wv_model.most_similar(positive=[''], negative=[])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0JaMUyPGiwKz","colab_type":"code","colab":{}},"source":["print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"],"execution_count":0,"outputs":[]}]}